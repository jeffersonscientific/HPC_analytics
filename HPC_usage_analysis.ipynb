{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy\n",
    "import matplotlib\n",
    "import matplotlib.dates as mpd\n",
    "import pylab as plt\n",
    "import datetime as dtm\n",
    "import multiprocessing as mpp\n",
    "import pickle\n",
    "#\n",
    "# TODO: phase out unreferenced hpc_lib calls...\n",
    "import hpc_lib\n",
    "#from hpc_lib import SACCT_data_handler\n",
    "from hpc_lib import *\n",
    "#\n",
    "import pandas\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#\n",
    "# get header, print a few rows:\n",
    "#data_file_name = 'data/sacct_out.out'\n",
    "#data_file_name = 'data/sacct_mazama_out.out'\n",
    "data_file_name = 'data/sacct_sherlock_out_hns.out'\n",
    "#data_file_name = 'data/sacct_sherlock_out_oneillm.out'\n",
    "#\n",
    "demo_file = 'data/demo_data.out'\n",
    "with open(data_file_name, 'r') as fin:\n",
    "    with open(demo_file,'w') as fout:\n",
    "        for k in range(int(1e5)):\n",
    "            fout.write(fin.readline())\n",
    "            #\n",
    "        #\n",
    "    #\n",
    "#\n",
    "#\n",
    "# translation dictionary. Note the column input parameters (aka, --format=...) are not the same as\n",
    "#.  the colunm names.\n",
    "#\n",
    "# with -p --delimiter='|', we get:\n",
    "#. ['User', 'JobID', 'JobName', 'Partition', 'State', 'Timelimit', 'Start', 'End',\n",
    "#'Elapsed', 'MaxRSS', 'MaxVMSize', 'NNodes', 'NCPUS', '']\n",
    "#\n",
    "# how well does PANDAS automagically handle types? Maybe we should just add all available columns to this:\n",
    "# NOTE: System-,User-,Total-CPU is a string with multiple values (time, energy, etc.)\n",
    "types_dict={'User':str, 'JobID':str, 'JobName':str, 'Partition':str, 'State':str,\n",
    "            'Timelimit':hpc_lib.elapsed_time_2_day,'Start':str2date, 'End':str2date, 'Submit':str2date,\n",
    "            'Elapsed':hpc_lib.elapsed_time_2_day, 'MaxRSS':str,\n",
    "            'MaxVMSize':str, 'NNodes':int, 'NCPUS':int, 'MinCPU':str, 'SystemCPU':str, 'UserCPU':str,\n",
    "            'TotalCPU':str}\n",
    "delim = '|'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How dtypes work in PANDAS:\n",
    "#\n",
    "# #data_df2['Submit']=mpd.datestr2num(data_df2['Submit'])\n",
    "# print('** ', data_df2.dtypes)\n",
    "# print('** ', data_df2.dtypes.index, data_df2.dtypes.values)\n",
    "# for s in data_df2.dtypes.index: print('* ', s)\n",
    "# print('** ** ', 'State' in data_df2.dtypes.index)\n",
    "#\n",
    "# print('** ', data_df2.columns )\n",
    "# print('** ', len(data_df2.columns))\n",
    "# #\n",
    "# for s in data_df2.columns:\n",
    "#     print('** ', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HPC Usage data\n",
    "- Presently focused on Mazama\n",
    "- Usage data drawn via:\n",
    "```\n",
    "--format=User,JobID,Jobname,partition,state,time,start,end,elapsed,MaxRss,MaxVMSize,nnodes,ncpus\n",
    "```\n",
    "- Generally, type conversions will need to be performed manually\n",
    "- But since we might change the columns of interest, let's code up a dictionary of functions to do the translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# with open(demo_file, 'r') as fin:\n",
    "#     # NOTE: lines end with a delimiter, so dump the last value.\n",
    "#     #\n",
    "#     headers = fin.readline()[:-1].split(delim)\n",
    "#     delim_lines=fin.readline()\n",
    "#     #\n",
    "#     #print('*** headers: ', headers)\n",
    "#     #\n",
    "#     teasers = []\n",
    "#     for k in range(10):\n",
    "#         #print('**')\n",
    "#         #teasers += [fin.readline()[:-1].split()]\n",
    "#         teasers += [fin.readline()[:-2]]\n",
    "# #\n",
    "# print('headers: ', headers)\n",
    "# for k,rw in enumerate(teasers):\n",
    "#     print('{}: {}'.format(k,rw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** DEBUG: jobs_summary.shape = (31736,)\n"
     ]
    }
   ],
   "source": [
    "sacct_demo = hpc_lib.SACCT_data_handler(data_file_name=demo_file, delim='|', max_rows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ff = sacct_demo.jobs_summary.tofile(fid='demo_summary.csv', )\n",
    "sacct_demo.jobs_summary.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sacct_data = SACCT_data_handler(data_file_name=demo_file, delim='|', max_rows=1000)\n",
    "sacct_data = hpc_lib.SACCT_data_handler(data_file_name=data_file_name, delim='|')\n",
    "#\n",
    "ts = sacct_demo.jobs_summary['Start'][0:10]\n",
    "print('** ', ts.shape)\n",
    "print('** ', sacct_data.jobs_summary.shape, sacct_data.data.shape)\n",
    "print('** ', sacct_data.data.dtype)\n",
    "print('** ', sacct_data.jobs_summary.dtype)\n",
    "print('\\n\\n** ', sacct_data.data['Start'][0])\n",
    "print('** ', sacct_data.jobs_summary['Start'][0])\n",
    "#\n",
    "print('** ', sacct_data.jobs_summary['Start'][0:10])\n",
    "print('** ', type(sacct_data.jobs_summary['Start'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/hns_summary_ary.pkl', 'wb') as fout:\n",
    "    out_pkl = pickle.dump(sacct_demo.jobs_summary, fout)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d_out = sacct_data.export_summary_data(output_path='data/hns_summary.csv')\n",
    "output_path = 'data/hns_summary_out.csv'\n",
    "delim = '\\t'\n",
    "print('** ', '%s{}'.format(delim))\n",
    "ss = '%s{}'.format(delim)\n",
    "print('** ** ', ss.join(['' for _ in sacct_data.headers]))\n",
    "\n",
    "print('* {} * {}'.format(len(sacct_data.headers), sacct_data.headers))\n",
    "print('* {} * {}'.format(len(sacct_data.jobs_summary[0]), sacct_data.jobs_summary[0]))\n",
    "\n",
    "xx =  sacct_data.jobs_summary.tofile(output_path,\n",
    "                                        format=('%s{}'.format(delim)).join(['' for _ in sacct_data.headers]),\n",
    "                                     sep='\\n')\n",
    "\n",
    "# with open('demo_summary.csv', 'r') as fin:\n",
    "#     #for k,rw in enumerate(fin):\n",
    "#     #    print('** ', rw)\n",
    "#     #    if k>10: break\n",
    "#     #    #\n",
    "#     #\n",
    "#     S = fin.read(800)\n",
    "#     print('** ', S)\n",
    "#     print('** * ', S.find('\\t'))\n",
    "# #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_usage = sacct_data.active_jobs_cpu()\n",
    "#cpu_usage = sacct_demo.active_jobs_cpu()\n",
    "\n",
    "fg = plt.figure(figsize=(12,10))\n",
    "ax1 = plt.subplot('211')\n",
    "ax2 = plt.subplot('212')\n",
    "#\n",
    "ax1.grid()\n",
    "ax2.grid()\n",
    "#\n",
    "ax1.plot(cpu_usage['time'], cpu_usage['N_jobs'], ls='-')\n",
    "ax2.plot(cpu_usage['time'], cpu_usage['N_cpu'], ls='-')\n",
    "#\n",
    "ax1.set_title('Jobs')\n",
    "ax1.set_ylabel('$N_{jobs}$')\n",
    "#\n",
    "ax2.set_title('CPUs')\n",
    "ax2.set_ylabel('$N_{CPU}')\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_wait_stats(self):\n",
    "#     wait_stats = numpy.core.records.fromarrays(numpy.zeros((len(self.jobs_summary), 6)).T, dtype=[('ncpus', '>i8'), ('mean', '>f8'), \n",
    "#                                                                     ('median', '>f8'),  ('stdev', '>f8'),\n",
    "#                                                                     ('min', '>f8'),  ('max', '>f8')])\n",
    "#     #\n",
    "#     delta_ts = self.jobs_summary['Start'] - self.jobs_summary['Submit']\n",
    "#     #\n",
    "#     for j,k in enumerate(sorted(numpy.unique(self.jobs_summary['NCPUS']) ) ):\n",
    "#         #\n",
    "#         x_prime = delta_ts[numpy.logical_and(self.jobs_summary['NCPUS']==k, delta_ts>=0.)]\n",
    "#         #wait_stats[k-1]=[[k, numpy.mean(x_prime), numpy.median(x_prime), numpy.std(x_prime), \n",
    "#         #                 numpy.min(x_prime), numpy.max(x_prime)]]\n",
    "#         #\n",
    "#         #wait_stats[k-1][0] = k\n",
    "#         wait_stats[j][0] = k\n",
    "#         if len(x_prime)==0:\n",
    "#             continue\n",
    "#         #\n",
    "#         for l,f in zip(range(1, 6), [numpy.mean, numpy.median, numpy.std, numpy.min, numpy.max]):\n",
    "#             #\n",
    "#             wait_stats[j][l]=f(x_prime)\n",
    "#         #\n",
    "#     #\n",
    "#     return wait_stats\n",
    "#\n",
    "wait_stats = sacct_data.get_wait_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Cumulative distributrions of wait times, as a function of n_cpu. Not trivially simple how we want \n",
    "#. to tell this story.\n",
    "#\n",
    "fg = plt.figure(figsize=(14,12))\n",
    "ax1 = plt.subplot('221')\n",
    "ax2 = plt.subplot('222')\n",
    "#\n",
    "ax3 = plt.subplot('223')\n",
    "ax4 = plt.subplot('224')\n",
    "#\n",
    "for ax in (ax1, ax2, ax3, ax4):\n",
    "    ax.grid()\n",
    "#\n",
    "quantiles = []\n",
    "quantiles_lt = []\n",
    "qs = [.5, .8, .95]\n",
    "\n",
    "#\n",
    "#len(numpy.unique(wait_stats['ncpus']))\n",
    "for n in (wait_stats['ncpus']):\n",
    "    if n==0: continue\n",
    "    #\n",
    "    \n",
    "    #n = int(n)\n",
    "    #X = wait_stats[wait_stats['ncpus']==n] \n",
    "    #\n",
    "    xx_gt = numpy.array(sorted( (sacct_data.jobs_summary['Start'] -\n",
    "                              sacct_data.jobs_summary['Submit'])[sacct_data.jobs_summary['NCPUS']>=n] ))\n",
    "    xx_lt = numpy.array(sorted( (sacct_data.jobs_summary['Start'] -\n",
    "                              sacct_data.jobs_summary['Submit'])[sacct_data.jobs_summary['NCPUS']==n] ))\n",
    "    quantiles += [[n] + list(numpy.quantile(xx_gt, qs))]\n",
    "    quantiles_lt += [[n] + list(numpy.quantile(xx_lt, qs))]\n",
    "    #\n",
    "    #print('*** ', n, len(xx) )\n",
    "    \n",
    "    #print('** {}/{}'.format(len(X), len(wait_stats)))\n",
    "    #\n",
    "    if n%5==0:\n",
    "        ax1.plot(xx_gt*24., numpy.linspace(0., 1., len(xx_gt)), ls='-', label='N_{{cpu}} = {}'.format(n))\n",
    "        #\n",
    "        ax3.plot(xx_lt*24., numpy.linspace(0., 1., len(xx_lt)), ls='-', label='N_{{cpu}} = {}'.format(n))\n",
    "#\n",
    "quantiles = numpy.array(quantiles)\n",
    "quantiles_lt = numpy.array(quantiles_lt)\n",
    "#\n",
    "ax1.legend(loc=0)\n",
    "ax1.set_xlim(0,72)\n",
    "#\n",
    "#\n",
    "for k,q in enumerate(qs):\n",
    "    print('*** ', k,q)\n",
    "    ax2.plot(quantiles[:,0], quantiles[:,2], label='$q={}$'.format(q), alpha=.7, color='b')\n",
    "    ax2.fill_between(quantiles[:,0], quantiles[:,1], quantiles[:,quantiles.shape[1]-1], alpha=.2, color='b')\n",
    "    #\n",
    "    ax4.plot(quantiles_lt[:,0], quantiles_lt[:,2], label='$q={}$'.format(q), alpha=.7, color='b')\n",
    "    ax4.fill_between(quantiles_lt[:,0], quantiles_lt[:,1],\n",
    "                     quantiles_lt[:,quantiles_lt.shape[1]-1], alpha=.2, color='b')\n",
    "#\n",
    "ax2.grid()\n",
    "ax2.set_ylim(0, 3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = plt.figure(figsize=(14,6))\n",
    "ax1 = plt.subplot('121')\n",
    "ax2 = plt.subplot('122')\n",
    "ax1.grid()\n",
    "ax2.grid()\n",
    "#\n",
    "time_limits = numpy.array([hpc_lib.elapsed_time_2_day(s) for s in sacct_data.jobs_summary['Timelimit']])\n",
    "req_volume = time_limits*sacct_data.jobs_summary['NCPUS']\n",
    "ix_sort = numpy.argsort(req_volume)\n",
    "#\n",
    "#hh = plt.hist(time_limits, 25, log=True)\n",
    "hh = ax1.hist(req_volume, 25, log=True)\n",
    "#\n",
    "dts = sacct_data.jobs_summary['Start']-sacct_data.jobs_summary['Submit']\n",
    "ax2.plot(req_volume[ix_sort], dts[ix_sort], ls='', marker='.')\n",
    "n=200\n",
    "ax2.plot((req_volume[ix_sort])[n:], hpc_lib.running_mean(dts[ix_sort],n), ls='-', marker='.', lw=3., zorder=11)\n",
    "ax2.set_ylim([-.2, 2.5])\n",
    "ax2.set_xlim(-10., 1000.)\n",
    "#\n",
    "print('*** ', sacct_data.jobs_summary['Timelimit'][0:10])\n",
    "#print('*** ', sacct_data.data['Timelimit'][0:10])\n",
    "print('** ', sacct_data.jobs_summary.dtype.names)\n",
    "#\n",
    "plt.suptitle('Job volume ($N_{cpu} \\cdot \\Delta t$) wait times')\n",
    "ax1.set_title('Wait time frequencies')\n",
    "ax1.set_xlabel('Job compute volume, ($N_{cpu} \\cdot \\Delta t$)')\n",
    "ax2.set_title('Wait times, $\\Delta t_w (N_{cpu} \\cdot \\Delta t)$')\n",
    "ax2.set_xlabel('Job compute volume, ($N_{cpu} \\cdot \\Delta t$)')\n",
    "ax2.set_ylabel('Submit wait time, $\\Delta t_w$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative distributrions of wait times, as a function of n_cpu*run-time. Not trivially simple how we want \n",
    "#. to tell this story.\n",
    "# note that this should be requested wall-time, but i'm not sure we have that.\n",
    "#\n",
    "fg = plt.figure(figsize=(14,12))\n",
    "ax1 = plt.subplot('221')\n",
    "ax2 = plt.subplot('222')\n",
    "#\n",
    "ax3 = plt.subplot('223')\n",
    "ax4 = plt.subplot('224')\n",
    "#\n",
    "for ax in (ax1, ax2, ax3, ax4):\n",
    "    ax.grid()\n",
    "#\n",
    "quantiles = []\n",
    "quantiles_lt = []\n",
    "qs = [.5, .75, .99]\n",
    "\n",
    "#\n",
    "#len(numpy.unique(wait_stats['ncpus']))\n",
    "for n in (wait_stats['ncpus']):\n",
    "    if n==0: continue\n",
    "    #\n",
    "    \n",
    "    #n = int(n)\n",
    "    #X = wait_stats[wait_stats['ncpus']==n] \n",
    "    #\n",
    "    xx_gt = numpy.array(sorted( (sacct_data.jobs_summary['Start'] -\n",
    "                              sacct_data.jobs_summary['Submit'])[sacct_data.jobs_summary['NCPUS']>=n] ))\n",
    "    xx_lt = numpy.array(sorted( (sacct_data.jobs_summary['Start'] -\n",
    "                              sacct_data.jobs_summary['Submit'])[sacct_data.jobs_summary['NCPUS']==n] ))\n",
    "    quantiles += [[n] + list(numpy.quantile(xx_gt, qs))]\n",
    "    quantiles_lt += [[n] + list(numpy.quantile(xx_lt, qs))]\n",
    "    #\n",
    "    #print('*** ', n, len(xx) )\n",
    "    \n",
    "    #print('** {}/{}'.format(len(X), len(wait_stats)))\n",
    "    #\n",
    "    if n%5==0:\n",
    "        ax1.plot(xx_gt*24., numpy.linspace(0., 1., len(xx_gt)), ls='-', label='N_{{cpu}} = {}'.format(n))\n",
    "        #\n",
    "        ax3.plot(xx_lt*24., numpy.linspace(0., 1., len(xx_lt)), ls='-', label='N_{{cpu}} = {}'.format(n))\n",
    "#\n",
    "quantiles = numpy.array(quantiles)\n",
    "quantiles_lt = numpy.array(quantiles_lt)\n",
    "#\n",
    "ax1.legend(loc=0)\n",
    "ax1.set_xlim(0,72)\n",
    "ax1.set_xlabel('Wait time (hours)')\n",
    "#\n",
    "#\n",
    "for k,q in enumerate(qs):\n",
    "    print('*** ', k,q)\n",
    "    ax2.plot(quantiles[:,0], quantiles[:,2], label='$q={}$'.format(q), alpha=.7, color='b')\n",
    "    ax2.fill_between(quantiles[:,0], quantiles[:,1], quantiles[:,quantiles.shape[1]-1], alpha=.2, color='b')\n",
    "    #\n",
    "    ax4.plot(quantiles_lt[:,0], quantiles_lt[:,2], label='$q={}$'.format(q), alpha=.7, color='b')\n",
    "    ax4.fill_between(quantiles_lt[:,0], quantiles_lt[:,1],\n",
    "                     quantiles_lt[:,quantiles_lt.shape[1]-1], alpha=.2, color='b')\n",
    "#\n",
    "ax2.grid()\n",
    "ax2.set_ylim(0, 3.)\n",
    "ax3.legend(loc=0)\n",
    "ax3.set_xlabel('Wait time (hours)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def submit_wait_times(self):\n",
    "#     submit_waits = self.summary_data['Start'] - self.summary_data['Submit']\n",
    "\n",
    "X,Y = [sacct_data.jobs_summary['NCPUS'], sacct_data.jobs_summary['Start']-sacct_data.jobs_summary['Submit']]\n",
    "ix = numpy.argsort(X)\n",
    "#\n",
    "fg = plt.figure(figsize=(14,6))\n",
    "ax1 = plt.subplot('121')\n",
    "ax2 = plt.subplot('122')\n",
    "ax1.grid()\n",
    "ax2.grid()\n",
    "#\n",
    "ax1.plot(X[ix], Y[ix], ls='', marker='.')\n",
    "#\n",
    "ax2.plot(wait_stats['ncpus'], wait_stats['median'], ls='', marker='o')\n",
    "ax2.plot(wait_stats['ncpus'], wait_stats['mean'], ls='', marker='o')\n",
    "ax2.set_yscale=('log')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('** ', sacct_data.jobs_summary['Start'][0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# unique completion states:\n",
    "data_df = sacct_data.data\n",
    "#\n",
    "#states = sorted(list(set([rw[RH['State']]  for rw in data])))\n",
    "states = sorted(list(set(data_df['State'])))\n",
    "for s in states:\n",
    "    print('** {}'.format(s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_groups = data_df.groupby(by=numpy.unique([s.split('.')[0] for s in data_df['JobID']]) )\n",
    "#my_groups = data_df.groupby(by=[s.split('.')[0] for s in data_df['JobID']] )\n",
    "ix_user_jobs = numpy.array([not ('.batch' in s or '.extern' in s) for s in data_df['JobID']])\n",
    "\n",
    "#group_index = {s:numpy.array([]) for s in numpy.unique([s.split('.')[0] for s in data_df['JobID'][ix_user_jobs] ])}\n",
    "job_ID_index = {s:[] for s in numpy.unique([s.split('.')[0] \n",
    "                                            for s in data_df['JobID'][ix_user_jobs] ])}\n",
    "\n",
    "\n",
    "for k,s in enumerate(data_df['JobID']):\n",
    "    job_ID_index[s.split('.')[0]] += [k]\n",
    "    #group_index[s.split('.')[0]] = numpy.append(group_index[s.split('.')[0]], [k])\n",
    "for ky,vl in job_ID_index.items():\n",
    "    job_ID_index[ky] = numpy.array(sorted(vl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Start':str2date, 'End':str2date, 'Submit':str2date, 'Elapsed'\n",
    "\n",
    "jobs_summary = numpy.recarray(shape=(len(job_ID_index), len(sacct_data.data.dtype)), dtype=data.dtype)\n",
    "for k, (j_id, ks) in enumerate(job_ID_index.items()):\n",
    "    jobs_summary[k]=data_df[numpy.min(ks)]\n",
    "    jobs_summary[k]['End'] = numpy.max(data_df['End'][ks])\n",
    "    jobs_summary[k]['Start'] = numpy.max(data_df['Start'][ks])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(my_groups))\n",
    "#print('** ', my_groups.count)\n",
    "#\n",
    "print('** ', len(group_index))\n",
    "print('** ', len(data_df['JobID']))\n",
    "#\n",
    "print('** ** ')\n",
    "\n",
    "for k, (ky,vl) in enumerate(group_index.items()):\n",
    "    print('* * ', ky, vl)\n",
    "    if k>10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('** {}\\n'.format(headers))\n",
    "# for rw in data[0:100]:\n",
    "#     if rw[RH['JobID']].split('.')[0]=='48057259_930':\n",
    "#         print('** {}\\n'.format(rw['Job']))\n",
    "#\n",
    "# this_jid = '48057259_930'\n",
    "this_jid = '48693050'\n",
    "this_jid = '48538697'\n",
    "for rw in data:\n",
    "    #print('** ', rw)\n",
    "    #print('* * ', rw[RH['JobID']])\n",
    "    #print('** ', rw[RH['JobID']].split('.'))\n",
    "    #if rw[RH['JobID']].split('.')[0]==this_jid:\n",
    "    if rw[RH['JobID']].startswith(this_jid) or rw[RH['JobID']] == this_jid:\n",
    "        #print('** {}'.format(rw[RH['JobID']]))\n",
    "        jid = rw[RH['JobID']]\n",
    "        #jid_0, jid_1 = rw[RH['JobID']].split('_')\n",
    "        # 'batch', 'extern', \n",
    "        if len(jid.split('.'))>=2 and jid.split('.')[1] in ('batch', 'extern', 'bogus_place_holder'):\n",
    "            continue\n",
    "        print('** {}\\n'.format([rw[RH[s]] for s in ('User', 'Group', 'JobID', 'Submit', 'Timelimit',\n",
    "                                  'Eligible', 'Start', 'End', 'Elapsed', 'NCPUS')]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Active CPUs:\n",
    "- TODO: this is overcounting cpus, because there is a row for each step in the job, but each step shows the full start/stop time.\n",
    "- We need to consolidate unique jobIDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "### how 'bout a time series of sum(ncpu) RUNNING?\n",
    "#\n",
    "# TODO: consider states COMPLETED, FAILED, RUNNING, TIMEOUT, PENDING. These all represent workload; only exclude\n",
    "#. canceled jobs.\n",
    "#ix = numpy.array([rw[RH['State']] in ['COMPLETED', 'RUNNING'] for rw in data])\n",
    "#ix = numpy.logical_or( data_df['State']=='COMPLETED', data_df['State']=='RUNNING')\n",
    "#ix = numpy.ones(len(data_df)).astype(bool)\n",
    "ix = numpy.array(['.batch' not in s and '.extern' not in s for s in data_df['JobID']])\n",
    "ix = numpy.array(['.' not in s for s in data_df['JobID']])\n",
    "ix_run = numpy.array(data_df['State']!='PENDING')\n",
    "ix = numpy.logical_and(ix, ix_run)\n",
    "#\n",
    "#\n",
    "t_now = mpd.date2num(dtm.datetime.now())\n",
    "t_start = mpd.date2num(data_df['Start'][ix])\n",
    "#\n",
    "t_end = data_df['End'][ix].to_numpy()\n",
    "t_end[t_end is None]=t_now\n",
    "t_end=mpd.date2num(t_end)\n",
    "#\n",
    "n_cpu = data_df['NCPUS'][ix].to_numpy()\n",
    "\n",
    "start_end = numpy.array([t_start, t_end]).T\n",
    "#\n",
    "# sort on t_start:\n",
    "start_end = start_end[numpy.argsort(start_end[:,0])]\n",
    "\n",
    "t_min = numpy.min(numpy.append(t_start, [x for x in t_end if not x is None] ))\n",
    "t_max = numpy.max(numpy.append(t_start, [x for x in t_end if not x is None] ))\n",
    "#\n",
    "# can also create X sequence like, for minute resolution\n",
    "# X = numpy.arange(t_min, t_max, 1./(24*60))\n",
    "X = numpy.linspace(t_min, t_max, 10000)\n",
    "#\n",
    "Ns = numpy.zeros(len(X))\n",
    "#\n",
    "Ns_cpu = numpy.zeros(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is many 100's of times faster than its cousin below:\n",
    "#Ns2 = numpy.zeros(len(X))\n",
    "#\n",
    "for j, (t_1, t_2, n) in enumerate(zip(t_start, t_end, n_cpu)):\n",
    "    #if j%25000==0:\n",
    "    #    print('j:: {}'.format(j))\n",
    "    #\n",
    "    # TODO: get more of the data set; we appear to be counting more cpus than exist?\n",
    "    # 1) check partition info, 2) maybe we're creating some sort of sampling error?\n",
    "    #.\n",
    "    ix = numpy.logical_and( X>=t_1, X<t_2)\n",
    "    Ns[ix] += 1\n",
    "    Ns_cpu[ix] += n\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = numpy.random.random(10)\n",
    "x2 = numpy.random.random(10)\n",
    "#\n",
    "print('x1: ', x1)\n",
    "print('x2: ', x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try another, should be more compute efficint way of computing running jobs/cpus:\n",
    "#. compute a sequence of started_jobs and a sequence of ended_jobs, then subtract.\n",
    "# to do the subtraction, interpolate onto a common time-axis.\n",
    "#\n",
    "# TODO: this general strategy is probably smarter for creating these working arrays, but for now just\n",
    "#. use th eexisting working arrays.\n",
    "# ix_active = numpy.logical_or(data_df['State']=='COMPLETED', data_df['State']=='RUNNING')\n",
    "# #\n",
    "# starts = numpy.array([(mpd.date2num(data_df[ix_active])['Start']), (data_df[ix_active])['NCPUS']])\n",
    "# #starts.sor\n",
    "# stops  = numpy.array([(mpd.date2num(data_df[ix_active])['End']), (data_df[ix_active])['NCPUS']])\n",
    "#\n",
    "import scipy.interpolate\n",
    "#\n",
    "ix_start = numpy.argsort(t_start)\n",
    "ix_end   = numpy.argsort(t_end)\n",
    "#\n",
    "ns_start = numpy.array([t_start[ix_start], numpy.cumsum(n_cpu[ix_start])])\n",
    "ns_end   = numpy.array([t_end[ix_end], numpy.cumsum(n_cpu[ix_end])])\n",
    "#\n",
    "f_start = scipy.interpolate.interp1d(ns_start[0], ns_start[1], fill_value=\"extrapolate\", bounds_error=False)\n",
    "f_end   = scipy.interpolate.interp1d(ns_end[0], ns_end[1], fill_value=\"extrapolate\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fg = plt.figure(figsize=(12, 10))\n",
    "ax1 = plt.subplot('211')\n",
    "ax1.grid()\n",
    "#\n",
    "ax2 = plt.subplot('223')\n",
    "ax2.grid()\n",
    "ax2.set_title('cpu starts')\n",
    "#\n",
    "ax3 = plt.subplot('224')\n",
    "ax3.grid()\n",
    "ax3.set_title('cpu completes')\n",
    "#\n",
    "#\n",
    "ax2.plot(*ns_start, ls='-', marker='')\n",
    "ax3.plot(*ns_end, ls='-', marker='')\n",
    "#\n",
    "X = numpy.linspace(numpy.min(numpy.array([t_start[ix_start], t_end[ix_end]])),\n",
    "                       numpy.max(numpy.array([t_start[ix_start], t_end[ix_end]])), 10000)\n",
    "ax2.plot(X, f_start(X), ls='--')\n",
    "ax3.plot(X, f_end(X), ls='--')\n",
    "#\n",
    "\n",
    "ax1.plot(X[:-1000], (f_start(X)-f_end(X))[:-1000], ls='-')\n",
    "ax1.set_title('Active CPUs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = plt.figure(figsize=(12,10))\n",
    "ax1 = plt.subplot('311')\n",
    "ax2 = plt.subplot('312', sharex=ax1)\n",
    "ax3 = plt.subplot('313', sharex=ax1)\n",
    "n_ave = 100\n",
    "#\n",
    "ln, = ax1.plot(X,Ns, ls='-', lw=1.5, marker='', alpha=.3)\n",
    "clr = ln.get_color()\n",
    "#\n",
    "Ns_sm = (numpy.cumsum(Ns)[n_ave:]-numpy.cumsum(Ns)[:-n_ave])/float(n_ave)\n",
    "ax1.plot(X[n_ave:], Ns_sm, color=clr,\n",
    "        ls='--', lw=2.)\n",
    "\n",
    "ln, = ax2.plot(X, Ns_cpu, ls='-', lw=3., marker='', alpha=.3)\n",
    "clr = ln.get_color()\n",
    "Ns_cpu_sm = (numpy.cumsum(Ns_cpu)[n_ave:]-numpy.cumsum(Ns_cpu)[:-n_ave])/float(n_ave)\n",
    "ax2.plot(X[n_ave:], Ns_cpu_sm, color=clr,\n",
    "        ls='--', lw=2.)\n",
    "\n",
    "ax3.plot(X[n_ave:], Ns_cpu_sm/Ns_sm, color=clr,\n",
    "        ls='--', lw=2.)\n",
    "\n",
    "#\n",
    "ax1.set_title('jobs running')\n",
    "ax2.set_title('cpu running')\n",
    "ax3.set_title('cpu/job')\n",
    "#\n",
    "ax1.grid()\n",
    "ax2.grid()\n",
    "ax3.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "86*24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#\n",
    "# delta_ts_all = numpy.array([elapsed_time_2_sec(rw[RH['Elapsed']]) for rw in data])\n",
    "# delta_ts_completed = numpy.array([elapsed_time_2_sec(rw[RH['Elapsed']]) \n",
    "#                                   for rw in data if rw[RH['State']]=='COMPLETED'])\n",
    "#\n",
    "delta_ts_all = numpy.array([rw[RH['Elapsed']] for rw in data])\n",
    "delta_ts_completed = numpy.array([rw[RH['Elapsed']] \n",
    "                                  for rw in data if rw[RH['State']]=='COMPLETED'])\n",
    "#\n",
    "print('*** lens: {}, {}'.format(len(delta_ts_all), len(delta_ts_completed)))\n",
    "#\n",
    "print(delta_ts_all[0:10])\n",
    "#\n",
    "fg = plt.figure(figsize=(12,10))\n",
    "ax = plt.subplot('111')\n",
    "#\n",
    "do_normed = True\n",
    "do_log    = False\n",
    "do_cum    = True\n",
    "h_type  = 'step'\n",
    "time_factor=1.0/(24.*3600)\n",
    "#\n",
    "hh_all  = ax.hist(delta_ts_all*time_factor, bins=50, log=do_log, cumulative=do_cum, histtype=h_type, normed=do_normed,\n",
    "                  label='all jobs')\n",
    "hh_comp = ax.hist(delta_ts_completed*time_factor, bins=50, log=do_log, cumulative=do_cum, histtype=h_type, normed=do_normed, \n",
    "                  label='completed')\n",
    "#\n",
    "ax.legend(loc=0)\n",
    "#\n",
    "ax.set_ylim(.99,1.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time delayed plots. aka, probability (or counts) of job times given jobs > t_min\n",
    "#\n",
    "fg = plt.figure(figsize=(12,10))\n",
    "ax = plt.subplot('111')\n",
    "#\n",
    "do_normed = False\n",
    "do_log    = False\n",
    "do_cum    = True\n",
    "h_type  = 'step'\n",
    "time_factor=1.0/(24.*3600)\n",
    "#\n",
    "delta_ts_completed = numpy.array([rw[RH['Elapsed']]\n",
    "                                      for rw in data if rw[RH['State']]=='COMPLETED'])\n",
    "for k,t_min in enumerate([0., 3600., 36000., 24.*3600, 5.*24.*3600, 7.*24.*3600]):\n",
    "    if k<2: continue\n",
    "\n",
    "    #delta_ts_all = numpy.array([elapsed_time_2_sec(rw[RH['Elapsed']]) for rw in data])\n",
    "    \n",
    "    #\n",
    "    #print('*** lens: {}, {}'.format(len(delta_ts_all), len(delta_ts_completed)))\n",
    "    #\n",
    "    #print(delta_ts[0:10])\n",
    "    #\n",
    "    #\n",
    "    #hh_all  = ax.hist(delta_ts_all*time_factor, bins=50, log=do_log, cumulative=do_cum, histtype=h_type, normed=do_normed,\n",
    "    #                  label='all jobs')\n",
    "    Y,X, patches = ax.hist(delta_ts_completed[delta_ts_completed>= t_min]*time_factor, bins=50,\n",
    "                           log=do_log, cumulative=do_cum, histtype=h_type, normed=do_normed, \n",
    "                      label='$t_{{min}}={}'.format(t_min*time_factor,))\n",
    "    #\n",
    "    # fill bewteen (approximate) dt=7 intersection and y.\n",
    "    k0 = numpy.argmin( (X-7.)**2. )\n",
    "    y0 = Y[k0]\n",
    "    clr = patches[0].get_edgecolor()\n",
    "    ix = X[:-1]>7.\n",
    "    #\n",
    "    X_prime = [X[k0]]\n",
    "    Y_prime = [Y[k0]]\n",
    "    for j, (x,y1,y2) in enumerate(zip(X[k0+1:], Y[k0:-1], Y[k0+1:])):\n",
    "        X_prime += [x, x]\n",
    "        Y_prime += [y1, y2]\n",
    "    #\n",
    "    #ax.fill_between(numpy.array(X[:-1])[ix], y0, Y[ix], color=clr, alpha=.1)\n",
    "    ax.fill_between(X_prime, y0, Y_prime, color=clr, alpha=.1)\n",
    "    #print('** ** ', len(ax.lines))\n",
    "    #\n",
    "ax.legend(loc=0)\n",
    "ax.grid()\n",
    "ax.plot([7., 7.], ax.get_ylim(), marker='.', ls='--', lw=2., color='m')\n",
    "ax.plot(ax.get_xlim(), [.9, .9], marker='', ls='--', lw=2., color='m')\n",
    "#\n",
    "ax.set_title('Cumulative Distribution of Job Lengths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time delayed plots. aka, probability (or counts) of job times given jobs > t_min\n",
    "#\n",
    "fg = plt.figure(figsize=(12,10))\n",
    "ax = plt.subplot('111')\n",
    "#\n",
    "do_normed = False\n",
    "do_log    = False\n",
    "do_cum    = True\n",
    "h_type  = 'step'\n",
    "time_factor=1.0/(24.*3600)\n",
    "#\n",
    "# usage index: dt*ncpus\n",
    "usage_index_completed = numpy.array([rw[RH['Elapsed']]*float(rw[RH['NCPUS']])\n",
    "                                      for rw in data if rw[RH['State']]=='COMPLETED'])\n",
    "for k,t_min in enumerate([0., 3600., 36000., 24.*3600, 5.*24.*3600, 7.*24.*3600]):\n",
    "    if k<1: continue\n",
    "\n",
    "    #delta_ts_all = numpy.array([elapsed_time_2_sec(rw[RH['Elapsed']]) for rw in data])\n",
    "    \n",
    "    #\n",
    "    #print('*** lens: {}, {}'.format(len(delta_ts_all), len(delta_ts_completed)))\n",
    "    #\n",
    "    #print(delta_ts[0:10])\n",
    "    #\n",
    "    #\n",
    "    #hh_all  = ax.hist(delta_ts_all*time_factor, bins=50, log=do_log, cumulative=do_cum, histtype=h_type, normed=do_normed,\n",
    "    #                  label='all jobs')\n",
    "    Y,X, patches = ax.hist(usage_index_completed[delta_ts_completed>= t_min]*time_factor, bins=50,\n",
    "                           log=do_log, cumulative=do_cum, histtype=h_type, normed=do_normed, \n",
    "                      label='$t_{{min}}={}$'.format(t_min*time_factor,))\n",
    "    #\n",
    "    # fill bewteen (approximate) dt=7 intersection and y.\n",
    "    k0 = numpy.argmin( (X-7.)**2. )\n",
    "    y0 = Y[k0]\n",
    "    clr = patches[0].get_edgecolor()\n",
    "    ix = X[:-1]>7.\n",
    "    #\n",
    "    X_prime = [X[k0]]\n",
    "    Y_prime = [Y[k0]]\n",
    "    for j, (x,y1,y2) in enumerate(zip(X[k0+1:], Y[k0:-1], Y[k0+1:])):\n",
    "        X_prime += [x, x]\n",
    "        Y_prime += [y1, y2]\n",
    "    #\n",
    "    #ax.fill_between(numpy.array(X[:-1])[ix], y0, Y[ix], color=clr, alpha=.1)\n",
    "    ax.fill_between(X_prime, y0, Y_prime, color=clr, alpha=.1)\n",
    "    #print('** ** ', len(ax.lines))\n",
    "    #\n",
    "ax.legend(loc=0)\n",
    "ax.grid()\n",
    "ax.plot([7., 7.], ax.get_ylim(), marker='.', ls='--', lw=2., color='m')\n",
    "ax.plot(ax.get_xlim(), [.9, .9], marker='', ls='--', lw=2., color='m')\n",
    "#\n",
    "ax.set_title('Cumulative Distribution of Usage-index ($\\Delta t \\cdot N_{cpu}$)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How 'bout some data on long jobs...\n",
    "#\n",
    "long_jobs = [rw for rw in data if rw[RH['Elapsed']]>7*24.*3600]\n",
    "#\n",
    "long_jobs_df = data_df[data_df['Elapsed']>7*24.*3600]\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partitions using long jobs:\n",
    "print(\"Long Job Partitons: \")\n",
    "print(\"len: \", len(long_jobs))\n",
    "print('partitions: ')\n",
    "#for rw in list(set([s[RH['Partition']] for s in long_jobs])):\n",
    "for rw in list(set(long_jobs_df['Partition'])):\n",
    "    print('** ', rw)\n",
    "    #\n",
    "#\n",
    "# partitions using long jobs:\n",
    "print(\"Long Job Users: \")\n",
    "print(\"len: \", len(long_jobs))\n",
    "print('Users: ')\n",
    "for rw in list(set(long_jobs_df['User'])):\n",
    "    print('** ', rw)\n",
    "    #\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_compute_vol = numpy.sum(data_df['NCPUS']*data_df['Elapsed'])\n",
    "ix = data_df['Elapsed']>(7.*24.*3600.)\n",
    "long_compute_vol = numpy.sum(data_df['NCPUS'][ix]*data_df['Elapsed'][ix])\n",
    "#\n",
    "print('** jobs: ', len(data), len(data_df[ix]), sum(ix), len(data_df[ix])/len(data))\n",
    "print('** compute tinme: ', numpy.sum(data_df['Elapsed']), numpy.sum(data_df['Elapsed'][ix]),\n",
    "      numpy.sum(data_df['Elapsed'][ix])/numpy.sum(data_df['Elapsed']))\n",
    "print('** compute volumnes: ', total_compute_vol, long_compute_vol, long_compute_vol/total_compute_vol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "ts = numpy.arange(1,40)\n",
    "lcvs = numpy.zeros(len(ts))\n",
    "mean_n_cpus = numpy.zeros(len(ts))\n",
    "stdev_n_cpus = numpy.zeros(len(ts))\n",
    "max_n_cpus = numpy.zeros(len(ts))\n",
    "median_n_cpus = numpy.zeros(len(ts))\n",
    "\n",
    "for k,t in enumerate(ts):\n",
    "    ix = data_df['Elapsed']>(t*24.*3600.)\n",
    "    lcv = numpy.sum(data_df['NCPUS'][ix]*data_df['Elapsed'][ix])\n",
    "    #\n",
    "    lcvs[k] = numpy.sum(numpy.sum(data_df['NCPUS'][ix]*data_df['Elapsed'][ix]))/total_compute_vol\n",
    "    #\n",
    "    mean_n_cpus[k]  = numpy.mean(data_df['NCPUS'][ix])\n",
    "    stdev_n_cpus[k] = numpy.std(data_df['NCPUS'][ix])\n",
    "    max_n_cpus[k] = numpy.max(data_df['NCPUS'][ix])\n",
    "    median_n_cpus[k] = numpy.median(data_df['NCPUS'][ix])\n",
    "    #\n",
    "#\n",
    "fg = plt.figure(figsize=(12,10))\n",
    "ax1 = plt.subplot('211')\n",
    "ax1.grid()\n",
    "ax2 = plt.subplot('212')\n",
    "ax2.grid()\n",
    "#\n",
    "ax1.plot(ts, lcvs, ls='-', marker='o', lw=3)\n",
    "ln, ax2.plot(ts, mean_n_cpus, ls='-', marker='o', lw=3)\n",
    "clr = ln.get_color()\n",
    "ax2.fill_between(ts, numpy.max([numpy.ones(len(ts)), mean_n_cpus-stdev_n_cpus], axis=0), mean_n_cpus+stdev_n_cpus, alpha=.2, color=clr)\n",
    "ax2.plot(ts, max_n_cpus, ls='--', marker='.', lw=2., alpha=.5)\n",
    "ax2.plot(ts, median_n_cpus, ls='--', marker='.', lw=2., alpha=.7, color=clr)\n",
    "#\n",
    "#\n",
    "n = 7\n",
    "ax1.plot([0., n], [lcvs[n-1], lcvs[n-1]], ls='--', lw=2., color='b')\n",
    "ax1.plot([n, n], [0., lcvs[n-1]], ls='--', lw=2., color='b')\n",
    "#\n",
    "n=14\n",
    "ax1.plot([0., n], [lcvs[n-1], lcvs[n-1]], ls='--', lw=2., color='c')\n",
    "ax1.plot([n, n], [0., lcvs[n-1]], ls='--', lw=2., color='c')\n",
    "#\n",
    "ax1.set_ylim(-.01, .3)\n",
    "#\n",
    "ax1.set_title('Fraction of jobs $\\Delta t > t$')\n",
    "ax1.set_ylabel('Fraction of long jobs')\n",
    "ax1.set_xlabel('Job length $t$ [days]')\n",
    "\n",
    "ax2.set_title('Number of CPU cores')\n",
    "ax2.set_ylabel('Number of CPUs $N_{cpu}$')\n",
    "ax2.set_xlabel('Job length $t$ [days]')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job wait times\n",
    "- Compute stats (mean, median, stdev) for wait times, as a function of the number of cores, $n_{cpu}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait times as a funciton of CPU.\n",
    "#\n",
    "delta_ts = mpd.date2num(data_df['Start']) - mpd.date2num(data_df['Submit'])\n",
    "#\n",
    "# do some binning and stats:\n",
    "#Ns_cpus = numpy.unique(dat_df['NCPUS'])\n",
    "Ns_cpu = numpy.arange(max(data_df['NCPUS']))+1\n",
    "# so we could spin through this and group all the data into bins, like:\n",
    "# 1: (x10, x11, x12..), 2:(x20, x21, x22...)\n",
    "# ... or we could sort the data and use a find_in_sorted() type function, but for\n",
    "#. now, i think it will be sufficient to just spin through the list a few times and use an index:\n",
    "#\n",
    "wait_stats = numpy.core.records.fromarrays(numpy.zeros((len(Ns_cpu), 6)).T, dtype=[('n', '>f8'), ('mean', '>f8'), \n",
    "                                                                ('median', '>f8'),  ('stdev', '>f8'),\n",
    "                                                                ('min', '>f8'),  ('max', '>f8')])\n",
    "#\n",
    "for k in Ns_cpu:\n",
    "    #x_prime = delta_ts[data_df['NCPUS']==k]\n",
    "    x_prime = delta_ts[numpy.logical_and(data_df['NCPUS']==k, delta_ts>=0.)]\n",
    "    #wait_stats[k-1]=[[k, numpy.mean(x_prime), numpy.median(x_prime), numpy.std(x_prime), \n",
    "    #                 numpy.min(x_prime), numpy.max(x_prime)]]\n",
    "    wait_stats[k-1][0] = k\n",
    "    if len(x_prime)==0:\n",
    "        continue\n",
    "    \n",
    "    for j,f in zip(range(1, 6), [numpy.mean, numpy.median, numpy.std, numpy.min, numpy.max]):\n",
    "        #\n",
    "        wait_stats[k-1][j]=f(x_prime)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('** ', 1./(24*60) )\n",
    "print('** ', .0007*24.*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# make a step-function of median wait times:\n",
    "#step_meds = [[0,0]]\n",
    "step_meds=[]\n",
    "for x,y in zip(Ns_cpu, wait_stats['median']):\n",
    "    #x0 = step_meds[-1][0]\n",
    "    step_meds += [[x-1, 0], [x-1, y], [x,y], [x,0]]\n",
    "step_meds = numpy.array(step_meds)\n",
    "#\n",
    "fg = plt.figure(figsize=(12,8))\n",
    "ax1 = plt.subplot('211')\n",
    "#ax1 = plt.subplot('111')\n",
    "ax2 = plt.subplot('212', sharex=ax1)\n",
    "#\n",
    "#ln, = ax1.plot(Ns_cpu, wait_stats['mean'])\n",
    "clr = ln.get_color()\n",
    "#ax1.plot(Ns_cpu, wait_stats['median'], color=clr, ls='-')\n",
    "#ax1.plot(Ns_cpu, wait_stats['mean'], color=None, ls='--')\n",
    "#ax1.fill_between(Ns_cpu, wait_stats['median'], wait_stats['median']+wait_stats['stdev'], color=clr, alpha=.2)\n",
    "ax1.plot(*step_meds.T, ls='-', marker='')\n",
    "#\n",
    "ix = wait_stats['mean']>0.\n",
    "ln2, = ax2.plot(Ns_cpu[ix], 24.*wait_stats['median'][ix], marker='.', ls='-')\n",
    "clr2=ln2.get_color()\n",
    "#\n",
    "ix = wait_stats['mean']>0.\n",
    "ax2.errorbar((Ns_cpu)[ix], 24.*(wait_stats['median'])[ix], 24.*(wait_stats['stdev'])[ix],\n",
    "             color=clr2, ls='', alpha=.2)\n",
    "#\n",
    "#ax2.plot(data_df['NCPUS'], delta_ts, ls='', marker='.')\n",
    "#\n",
    "ax1.grid()\n",
    "ax1.set_xlabel('Number of Cores $N_{cpu}$')\n",
    "ax1.set_ylabel('Wait time to start (in days)')\n",
    "#ax1.set_ylim(0., .0005)\n",
    "ax1.set_yscale('log')\n",
    "#ax2.set_yscale('log')\n",
    "#\n",
    "ax2.set_ylim(-.2, 6.0)\n",
    "ax2.grid()\n",
    "ax2.set_ylabel('wait time, hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sorted = pandas.DataFrame(sorted(sacct_data.data, key=lambda rw: rw[sacct_data.RH['JobID']]), columns=active_headers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = ['.' in s and not ( '.batch' in s or '.extern' in s) for s in data_sorted['JobID']]\n",
    "print('** :\\n', (data_sorted.iloc[ix, [RH[s] \n",
    "                                        for s in ['JobName', 'JobID', 'JobIDRaw',\n",
    "                                                  'Elapsed']]])[0:20] )\n",
    "# , 'CPUTimeRAW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ix = numpy.array([s.startswith('48057259') \n",
    "ix = numpy.array(['48270204' in s \n",
    "                                         and not ('.batch' in s \n",
    "                                         or '.extern' in s) for s in data_sorted['JobID']])\n",
    "\n",
    "print(data_sorted['JobID'][ix])\n",
    "#print(data_sorted['JobID'][ numpy.array(['48057259' in s for s in data_sorted['JobID']])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_sorted.loc[ix, ['JobID','NCPUS', 'Start', 'End', 'Elapsed','TotalCPU', 'State'] ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
