{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPC Analytics Template Notebook\n",
    "\n",
    "## Basic Idea\n",
    "- Create a private repo\n",
    "- submodule hpc_analytics into that repo\n",
    "- Copy this template into that notebook\n",
    "- Customize as need be...\n",
    "- run reports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy\n",
    "import math\n",
    "import matplotlib as mpl\n",
    "import matplotlib.dates as mpd\n",
    "import pylab as plt\n",
    "import datetime as dtm\n",
    "import pytz\n",
    "import multiprocessing as mpp\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import h5py\n",
    "#import socket\n",
    "#import lmod\n",
    "# lmod.load('system')\n",
    "# lmod.load('texlive')\n",
    "# lmod.\n",
    "#\n",
    "# TODO: phase out unreferenced hpc_lib calls...\n",
    "import HPC_analytics.hpc_lib as hpc_lib\n",
    "GB=1024.**3.\n",
    "#import HPC_analytics.hpc_reports as hpc_reports\n",
    "#\n",
    "# def running_mean(X,n=10):\n",
    "#     return (numpy.cumsum(numpy.insert(X,0,0))[n:] - numpy.cumsum(numpy.insert(X,0,0))[:-n])/n\n",
    "# #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import socket\n",
    "# socket.gethostname()\n",
    "# CPU cores: 7712\n",
    "# GPU cores: 1344?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cpus = 4\n",
    "#print('** epoch: {}'.format(mpd.get_epoch()))\n",
    "if 'SLURM_CPUS_PER_TASK' in os.environ.keys():\n",
    "    n_cpus = int(os.environ['SLURM_CPUS_PER_TASK'])\n",
    "#\n",
    "print(f'*** n_cpus: {n_cpus}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_report_len = 180\n",
    "end_dtm = dtm.datetime(2025,7,15)\n",
    "end_date = end_dtm.date()\n",
    "start_date = end_date - dtm.timedelta(days=N_report_len)\n",
    "print('*** dates: {} - {}'.format(start_date, end_date))\n",
    "#delim_sacct='|'\n",
    "delim_sacct='*'\n",
    "#partition='normal'\n",
    "partition='hns'\n",
    "#partition=None\n",
    "group=None\n",
    "s_user=None\n",
    "verbose=0\n",
    "# group='oneillm'\n",
    "# group='edunham'\n",
    "#s_user = 'labraha2'\n",
    "#\n",
    "SACCT_data_path = os.path.join(os.environ['SCRATCH'], 'SACCT', 'sacct_data')\n",
    "#SACCT_data_path='./sacct_data'\n",
    "sacct_h5_file_name = f'sacct_sherlock_p{str(partition).upper()}_g{str(group).upper()}_u{s_user}_{start_date.year:04}{start_date.month:02}{start_date.day:02}_{end_dtm.year:04}{end_dtm.month:02}{end_dtm.day:02}.h5'\n",
    "#\n",
    "sacct_h5_file = os.path.join(SACCT_data_path, sacct_h5_file_name)\n",
    "print(f'*** sacct_h5_file [{os.path.isfile(sacct_h5_file)}]: {sacct_h5_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('** ', sacct_h5_file)\n",
    "print('** ', os.path.split(sacct_h5_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# NOTE: to get individual users, eg to get Eric's group usage:\n",
    "#. sacct --allusers --user=labraha2 --start=2022-01-01 --end=2022-06-15\n",
    "#\n",
    "# NOTE: additional options can be passed in the more_options=[] arrary, or just as sacct_{option-name}={val}\n",
    "#\n",
    "if os.path.isfile(sacct_h5_file):\n",
    "    print('*** Creating SACCT object from HDF5 {}'.format(sacct_h5_file))\n",
    "    SACCT_obj = hpc_lib.SACCT_data_from_h5(sacct_h5_file, keep_raw_data=False, n_cpu=n_cpus)\n",
    "    #\n",
    "    \n",
    "else:\n",
    "    print('*** Fetching SACCT data directly')\n",
    "    SACCT_obj = hpc_lib.SACCT_data_direct(group=group, partition=partition, start_date=str(start_date),\n",
    "                                          n_cpu=n_cpus, verbose=verbose, delim=delim_sacct,\n",
    "                                          end_date=str(end_date), keep_raw_data=False)\n",
    "    # , sacct_user=s_user\n",
    "    print(f'** writing HDF5: {sacct_h5_file}')\n",
    "    pth, fn = os.path.split(sacct_h5_file)\n",
    "    if not os.path.isdir(pth):\n",
    "        os.makedirs(pth)\n",
    "    \n",
    "    SACCT_obj.write_hdf5(sacct_h5_file)\n",
    "    #\n",
    "#\n",
    "print('** ', SACCT_obj.jobs_summary.dtype.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import h5py\n",
    "print('** ', h5py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP=hpc_lib.SH_PART_obj()\n",
    "#\n",
    "# SH_PART will only show partitions of which caller/user is a member. For more general applications, use\n",
    "#. SINFO_obj()\n",
    "SIo = hpc_lib.SINFO_obj(partition=partition, Format_fields='node')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('** ', SIo.total_cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('** cols: ', SIo.sinfo_data.dtype.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cpus  = SIo.total_cpus\n",
    "total_nodes = SIo.total_nodes\n",
    "total_gpus  = SIo.get_total_cpus('GPUS')\n",
    "\n",
    "\n",
    "print(f'** partition: {partition}')\n",
    "print(f'*** Cols: {SACCT_obj.jobs_summary.dtype.names}')\n",
    "print(f'*** CPUs: {total_cpus}')\n",
    "print(f'*** Nodes: {total_nodes}')\n",
    "#\n",
    "# note, all methods of computing N_GPUs appear to agree\n",
    "print(f'*** GPUs: {total_gpus}, {numpy.sum(SIo.sinfo_data[\"GPUS\"])}, {SIo.get_total_cpus(\"GPUS\")}')\n",
    "\n",
    "unique_users = numpy.unique(SACCT_obj['User'])\n",
    "print(f'** len: {len(unique_users)} users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_cpus_serc = SP.get_total_cpus(partitions=partition)\n",
    "#n_gpus_serc = SP.get_total_gpus(partitions=partition)\n",
    "\n",
    "n_cpus_serc = total_cpus\n",
    "n_gpus_serc = total_gpus\n",
    "\n",
    "#\n",
    "print(f'** n_cpus: {n_cpus_serc}, n_gpus: {n_gpus_serc}')\n",
    "#\n",
    "#print('*** ', SP.SP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('** ', SACCT_obj.jobs_summary.dtype)\n",
    "print('** ', type(SACCT_obj.jobs_summary['User'][0]))\n",
    "#\n",
    "# my_ary = numpy.array(len(SACCT_obj.jobs_summary), dtype=SACCT_obj.jobs_summary.dtype)\n",
    "# print('** ', my_ary.dtype)\n",
    "#\n",
    "for cl,tp in SACCT_obj.jobs_summary.dtype.descr:\n",
    "    print('** ', cl, tp)\n",
    "    \n",
    "#\n",
    "print('** ** ', SACCT_obj.jobs_summary['Group'].astype(str)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rep_cpu_lc = SACCT_obj.report_activecpus_jobs_layercake_and_CDFs(group_by='Partition', trendline=True)\n",
    "#\n",
    "# plot total CPUs in partition. Also, subtract CPUs associated with GPUs. For now, this is just\n",
    "#. something we know. we will need to work harder to get it from data.\n",
    "ax = rep_cpu_lc.axes[0]\n",
    "ln = ax.lines[0]\n",
    "#\n",
    "x_max_cpus = numpy.array([ax.lines[0].get_xdata()[0], ax.lines[0].get_xdata()[-1]])\n",
    "ax.plot( x_max_cpus, numpy.ones(2)*n_cpus_serc, ls='--', lw=3.,\n",
    "       color='r', label='+GPUs')\n",
    "\n",
    "# TODO: smarter waty to count GPU-CPUs in SINFO...\n",
    "ax.plot( x_max_cpus, numpy.ones(2)*n_cpus_serc-(10*128 + 2*24 + 2*64), ls='--', lw=3.,\n",
    "       color='m', label='CPUs')\n",
    "#\n",
    "# ax.plot( x_max_cpus, numpy.ones(2)*n_cpus_serc-(10*128 + 2*24 + 96*32), ls='--', lw=3.,\n",
    "#        color='c', label='CPUs (old SERC)')\n",
    "\n",
    "ax.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('** ', SACCT_obj.jobs_summary.dtype.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Active CPUs and quantiels for CPU Only jobs:\n",
    "ix = SACCT_obj['NGPUs']==0\n",
    "rep_cpu_CPU_jobs = SACCT_obj.report_activecpus_jobs_layercake_and_CDFs(group_by='Partition',\n",
    "                                                jobs_summary=SACCT_obj[ix], trendline=True)\n",
    "fg = rep_cpu_CPU_jobs\n",
    "ax = rep_cpu_CPU_jobs.axes[0]\n",
    "ln = ax.lines[0]\n",
    "#\n",
    "N_cpu_cpus = n_cpus_serc-(10*128 + 2*24 + 1*64)\n",
    "#\n",
    "x_max_cpus = numpy.array([ax.lines[0].get_xdata()[0], ax.lines[0].get_xdata()[-1]])\n",
    "ax.plot( x_max_cpus, numpy.ones(2)*N_cpu_cpus, ls='--', lw=3.,\n",
    "       color='m', label=f'CPUs: {N_cpu_cpus}')\n",
    "fg.suptitle('CPU Jobs (GPUs excluded)', size=14)\n",
    "ax.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wait times (CPU only jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.sum(~numpy.isnan(SACCT_obj['End']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_wt_cpu = numpy.logical_and(SACCT_obj['NGPUs']==0, ~numpy.isnan(SACCT_obj['End']))\n",
    "ix_wt_gpu = numpy.logical_and(SACCT_obj['NGPUs']>0, ~numpy.isnan(SACCT_obj['End']))\n",
    "#\n",
    "wait_times_cpu = 24.*(SACCT_obj['End'][ix_wt_cpu] - SACCT_obj['Start'][ix_wt_cpu])\n",
    "wait_times_gpu = 24.*(SACCT_obj['End'][ix_wt_gpu] - SACCT_obj['Start'][ix_wt_gpu])\n",
    "#\n",
    "q_steps = [.5, .75, .9, .99]\n",
    "qs_cpu = numpy.quantile(wait_times_cpu[~numpy.isnan(wait_times_cpu)], q_steps)\n",
    "qs_gpu = numpy.quantile(wait_times_gpu[~numpy.isnan(wait_times_gpu)], q_steps)\n",
    "#\n",
    "print('CPUs: \\n', qs_cpu)\n",
    "print('GPUs: \\n', qs_gpu)\n",
    "#\n",
    "fg = plt.figure(figsize=(12,10))\n",
    "ax1 = fg.add_subplot(1,2,1)\n",
    "ax2 = fg.add_subplot(1,2,2)\n",
    "#\n",
    "h1 = ax1.hist(wait_times_cpu, bins=100, cumulative=True, histtype='step', lw=3, density=True)\n",
    "h2 = ax2.hist(wait_times_gpu, bins=100, cumulative=True, histtype='step', lw=3, density=True)\n",
    "#\n",
    "for t,q in zip(qs_cpu, q_steps):\n",
    "    ax1.plot([t,t,0], [0,q,q], label=f'q_{int(100*q)}={t:.2f} hour')\n",
    "for t,q in zip(qs_gpu, q_steps):\n",
    "    ax2.plot([t,t,0], [0,q,q], label=f'q_{int(100*q)}={t:.2f} hour')\n",
    "\n",
    "ax1.set_title('Wait times, CPU jobs', size=16)\n",
    "ax2.set_title('Wait times, GPU jobs', size=16)\n",
    "ax1.legend(loc=0)\n",
    "ax2.legend(loc=0)\n",
    "ax1.grid()\n",
    "ax2.grid()\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#fg_cpuhl_acct = SACCT_obj.report_cpuhours_jobs_layercake_and_pie(group_by='Account')\n",
    "fg_cpu_lc_acct = SACCT_obj.report_activecpus_jobs_layercake_and_CDFs(group_by='Account')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total CPU hours, by group:\n",
    "#grp_total_cpuhours = numpy.zeros(len(numpy.unique(SACCT_obj['Account'])))\n",
    "grp_total_cpuhours = []\n",
    "SO = SACCT_obj\n",
    "#\n",
    "for grp in numpy.unique(SO['Account']):\n",
    "    #if isinstance(grp, bytes):\n",
    "    #    grp=grp.decode()\n",
    "    #print(f'*** {grp}' )\n",
    "    \n",
    "    #ix = SO['Account']==grp.encode()\n",
    "    ix = SO['Account']==grp\n",
    "    grp_total_cpuhours += [[grp, numpy.sum(SO['NCPUS'][ix] * SO['Elapsed'][ix]) ]]\n",
    "    #\n",
    "for k,(nm, x)in enumerate( sorted(grp_total_cpuhours, key=lambda rw:rw[1])[::-1] ):\n",
    "    print(f'[{k}] {nm}: {x:.2f} ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_total_cpuhours = []\n",
    "#SO = SACCT_obj[SACCT_obj['NGPUs']>0]\n",
    "SO = SACCT_obj\n",
    "#\n",
    "for grp in numpy.unique(SO['Account']):\n",
    "    #if isinstance(grp, bytes):\n",
    "    #    grp=grp.decode()\n",
    "    #print(f'*** {grp}' )\n",
    "    #ix = SO['Account']==grp.encode()\n",
    "    ix = numpy.logical_and(SO['Account']==grp, SO['NGPUs']>0)\n",
    "    grp_total_cpuhours += [[grp, numpy.sum(SO['NCPUS'][ix] * SO['Elapsed'][ix]),\n",
    "                            numpy.sum(SO['NGPUs'][ix] * SO['Elapsed'][ix]) ]]\n",
    "    #\n",
    "print('** group: cpu-hours  gpu-hours')\n",
    "for k,(nm, c, g)in enumerate( sorted(grp_total_cpuhours, key=lambda rw:rw[2])[::-1] ):\n",
    "    if g==0.: continue\n",
    "    print(f'[{k}] {nm}: {c:.2f}, {g:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU-hours distribution\n",
    "This will be a sort of odd distribution, I think. The idea is to capture how much of our compute is executed on how many cpus or nodes, so we can be better informed as to what sort of HW to buy.\n",
    "\n",
    "So the idea will be aggregate `CPUs x hours` in bins of `ncpus` or `nnodes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('** ', SACCT_obj.jobs_summary.dtype.names)\n",
    "print('**\\n**\\n')\n",
    "print(numpy.unique(SACCT_obj['NCPUS']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_hours_dist   = numpy.zeros(len(numpy.unique(SACCT_obj['NCPUS'])), dtype=[('NCPUS', '<i8'),\n",
    "                                                                ('hours', '<f8'), ('totalcpu', '<f8')])\n",
    "cpu_hours_dist['NCPUS'] = numpy.unique(SACCT_obj['NCPUS'])\n",
    "\n",
    "node_hours_dist = numpy.zeros(len(numpy.unique(SACCT_obj['NNodes'])), dtype=[('NNodes', '<i8'),\n",
    "                                                                ('hours', '<f8'), ('totalcpu', '<f8')])\n",
    "node_hours_dist['NNodes'] = numpy.unique(SACCT_obj['NNodes'])\n",
    "#\n",
    "#unique_ntasks = numpy.unique((SACCT_obj['NTasks'])[SACCT_obj['NTasks']>0])\n",
    "unique_ntasks = numpy.unique((SACCT_obj['NTasks']))\n",
    "tasks_hours_dist = numpy.zeros(len(unique_ntasks), dtype=[('NTasks', '<i8'),\n",
    "                                                                ('hours', '<f8'), ('totalcpu', '<f8')])\n",
    "tasks_hours_dist['NTasks'] = unique_ntasks\n",
    "#\n",
    "# Ok... probably should have started with a dict, then translated to an array, or use PANDAS. Or use a full\n",
    "# range() of index values, so we can just use spatial indexing, but we're not. We'll just use dict() as \n",
    "# an index to assign aggregates.\n",
    "#\n",
    "# also, this will not be the fastest way to do this, but it should be fairly straight forward.\n",
    "ix_cpus  = {n:k for k,n in enumerate(cpu_hours_dist['NCPUS'])}\n",
    "ix_nodes = {n:k for k,n in enumerate(node_hours_dist['NNodes'])}\n",
    "ix_tasks = {n:k for k,n in enumerate(tasks_hours_dist['NTasks'])}\n",
    "for rw in SACCT_obj:\n",
    "    #print('** ')\n",
    "    this_cpuh = rw['Elapsed']*rw['NCPUS']\n",
    "    for var,ix,cl in [(cpu_hours_dist, ix_cpus, 'NCPUS'), (node_hours_dist, ix_nodes, 'NNodes'),\n",
    "                      (tasks_hours_dist, ix_tasks, 'NTasks')]:\n",
    "        if numpy.isnan(rw[cl]):\n",
    "            continue\n",
    "        var['hours'][ix[int(rw[cl])]] += this_cpuh\n",
    "        var['totalcpu'][ix[int(rw[cl])]] += rw['TotalCPU']\n",
    "    #cpu_hours_dist['hours'][ix_cpus[int(rw['NCPUS'])]] += this_cpuh\n",
    "    #node_hours_dist['hours'][ix_nodes[int(rw['NNodes'])]] += this_cpuh\n",
    "    #tasks_hours_dist['hours'][ix_tasks[int(rw['NTasks'])]] += this_cpuh\n",
    "    #\n",
    "    # this is effectively a \"jobwise\" average. Or we just collect ['TotalCPU'] and divide at the end...\n",
    "    #tasks_hours_dist['eff'][ix_tasks[int(rw['NTasks'])]] += rw['TotalCPU']/(['Elapsed']*rw['NCPUS'])\n",
    "    #cpu_hours_dist['totalcpu'][ix_cpus[int(rw['NCPUS'])]] += rw['TotalCPU']\n",
    "    #node_hours_dist['totalcpu'][ix_nodes[int(rw['NNodes'])]] += rw['TotalCPU']\n",
    "    #tasks_hours_dist['totalcpu'][ix_tasks[int(rw['NTasks'])]] += rw['TotalCPU']\n",
    "#\n",
    "tasks_hours_dist = tasks_hours_dist[tasks_hours_dist['NTasks']>0]\n",
    "\n",
    "cpu_hours_dist['hours'] = numpy.cumsum(cpu_hours_dist['hours'])\n",
    "node_hours_dist['hours'] = numpy.cumsum(node_hours_dist['hours'])\n",
    "tasks_hours_dist['hours'] = numpy.cumsum(tasks_hours_dist['hours'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "qs = numpy.array([.5, .75, .9])\n",
    "fg = plt.figure(figsize=(14,6))\n",
    "#\n",
    "ax1 = fg.add_subplot(1,3,1)\n",
    "ax2 = fg.add_subplot(1,3,2)\n",
    "ax3 = fg.add_subplot(1,3,3)\n",
    "#\n",
    "axs = [ax1, ax2, ax3]\n",
    "#\n",
    "fg.suptitle('CPU-hours CDFs')\n",
    "for ax,ttl, in zip(axs, ['Per NCPU', 'Per Node', 'Per Task']):\n",
    "    ax.set_title(ttl)\n",
    "    ax.grid()\n",
    "    #\n",
    "X = cpu_hours_dist['NCPUS']\n",
    "Y = cpu_hours_dist['hours']\n",
    "#quants = numpy.quantile(Y, qs)\n",
    "quants = numpy.nanmax(Y)*qs\n",
    "ax = ax1\n",
    "ax.plot(X,Y)\n",
    "ks = Y.searchsorted(quants)\n",
    "#\n",
    "ax.set_xlabel('NCPUs', size=16)\n",
    "ax.set_ylabel('$CPUs \\cdot hours$', size=16)\n",
    "for k,(j,y) in enumerate(zip(Y.searchsorted(quants), quants)):\n",
    "    x = numpy.mean(X[j-1:j+1])\n",
    "    ax.plot([x,x,numpy.min(X)], [numpy.min(Y),y,y], ls='-', label=f'q: {qs[k]}={x}')\n",
    "ax.legend(loc=0)\n",
    "###########\n",
    "#\n",
    "X,Y = node_hours_dist['NNodes'], node_hours_dist['hours']\n",
    "quants = numpy.nanmax(Y)*qs\n",
    "ax = ax2\n",
    "#\n",
    "ax.plot(X,Y)\n",
    "ax.set_xlabel('N_Nodes', size=16)\n",
    "#ax.set_ylabel('$Nodes \\cdot hours$', size=16)\n",
    "for k,(j,y) in enumerate(zip(node_hours_dist['hours'].searchsorted(quants), quants)):\n",
    "    x = numpy.mean(X[j-1:j+1])\n",
    "    ax.plot([x,x,numpy.min(X)], [numpy.min(Y),y,y], ls='-', label=f'q: {qs[k]}={x}')\n",
    "ax.legend(loc='lower right')\n",
    "################\n",
    "#\n",
    "X,Y = tasks_hours_dist['NTasks'], tasks_hours_dist['hours']\n",
    "quants = numpy.nanmax(Y)*qs\n",
    "ax = ax3\n",
    "#\n",
    "ax.plot(X,Y)\n",
    "ax.set_xlabel('N_Tasks', size=16)\n",
    "#ax.set_ylabel('$Tasks \\cdot hours$', size=16)\n",
    "for k,(j,y) in enumerate(zip(Y.searchsorted(quants), quants)):\n",
    "    x = numpy.mean(X[j-1:j+1])\n",
    "    ax.plot([x,x,numpy.min(X)], [numpy.min(Y),y,y], ls='-', label=f'q: {qs[k]}={x}')\n",
    "ax.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_var in ['NCPUS', 'NNodes', 'NTasks']:\n",
    "    \n",
    "    SO = SACCT_obj[SACCT_obj[x_var]==1]\n",
    "    cpudays_one_task = numpy.sum(SO['NCPUS']*SO['Elapsed'])\n",
    "    cpudays_all      = numpy.sum(SACCT_obj['NCPUS']*SACCT_obj['Elapsed'])\n",
    "    print(f'** {x_var}:: one: {24.*cpudays_one_task:.2f}, all: {24.*cpudays_all:.2f}: fract: {cpudays_one_task/cpudays_all:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU Efficiency distribution(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = plt.figure(figsize=(8,6))\n",
    "ax = plt.gca()\n",
    "ax.grid()\n",
    "#\n",
    "eff = tasks_hours_dist['totalcpu']/tasks_hours_dist['hours']\n",
    "#\n",
    "ax.plot(cpu_hours_dist['NCPUS'][0:],    (cpu_hours_dist['totalcpu']/cpu_hours_dist['hours'])[0:],\n",
    "        marker='o', ls='-', label='cpus')\n",
    "ax.plot(node_hours_dist['NNodes'][0:], (node_hours_dist['totalcpu']/node_hours_dist['hours'])[0:],\n",
    "        marker='o', ls='-', label='nodes')\n",
    "ax.plot(tasks_hours_dist['NTasks'][0:], (tasks_hours_dist['totalcpu']/tasks_hours_dist['hours'])[0:],\n",
    "        marker='o', ls='-', label='tasks')\n",
    "ax.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User stat table\n",
    "- Generate a table of summary user stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "cpuh_pie_user = hpc_lib.get_pie_slices(sum_data=SACCT_obj['Elapsed']*SACCT_obj['NCPUS'],\n",
    "                                       slice_data=SACCT_obj['User'])\n",
    "jobs_pie_user = hpc_lib.get_pie_slices(sum_data=SACCT_obj['Elapsed'], slice_data=SACCT_obj['User'])\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This will be way too big to produce in notebooks, practically speaking at least..\n",
    "# or maybe not, but we should do it last?\n",
    "t0 = mpd.date2num(start_date)\n",
    "t1 = mpd.date2num(end_date)\n",
    "delim = chr(9)\n",
    "delim = ';'\n",
    "print('*** CPU-hours: ')\n",
    "#print('**  Name,   cpu-hours,    job-hours,  last_job_start', )\n",
    "print(delim.join(['Name', 'cpu-hours', 'job-hours', 'n_jobs', 'last_job_start', 'Group', 'Accounts', 'Partitions']))\n",
    "jindex = {nm:k for k,nm in enumerate(jobs_pie_user['name'].astype(str))}\n",
    "#print('** jindex: ', jindex)\n",
    "for k, (nm,n) in enumerate(cpuh_pie_user[numpy.argsort(cpuh_pie_user['value'])[::-1]] ):\n",
    "    if k>10: break\n",
    "    #\n",
    "    ix = SACCT_obj['User'].astype(type(nm)) == nm\n",
    "    fg = plt.figure(figsize=(10,4))\n",
    "    ax = fg.add_subplot(1,1,1)\n",
    "    z = SACCT_obj.get_cpu_hours(jobs_summary=SACCT_obj[ix])\n",
    "    ax.plot(z['time'], z['cpu_hours'], ls='-', marker='')\n",
    "    ax.set_xlim(t0,t1)\n",
    "    ax.grid()\n",
    "    ax.set_xlabel('time $t$', size=16)\n",
    "    ax.set_ylabel('cpu-hours (per day?)', size=16)\n",
    "    #\n",
    "    if isinstance(nm,bytes):\n",
    "        nm = nm.decode()\n",
    "    #\n",
    "    ax.set_title(nm, size=16)\n",
    "    #\n",
    "    fg.canvas.draw()\n",
    "    dt_epoch = hpc_lib.compute_mpd_epoch_dt(z['time'][0])\n",
    "    lbls = [hpc_lib.simple_date_string(mpd.num2date(x + dt_epoch)) for x in ax.get_xticks()]\n",
    "#     lbls = [hpc_lib.simple_date_string(mpd.num2date(float(hpc_lib.fix_to_ascii(str(s.get_value()))) + dt_epoch) )\n",
    "#               for s in ax.get_xticklabels()]\n",
    "\n",
    "    #\n",
    "    #ax.set_xticklabels(lbls)\n",
    "    # This should get rid of the FixedLocator warning? But I'm not sure it will...\n",
    "    ticks_loc = ax.get_xticks().tolist()\n",
    "    ax.xaxis.set_major_locator(mpl.ticker.FixedLocator(ticks_loc))\n",
    "    ax.set_xticklabels(lbls)\n",
    "    #\n",
    "    rw_vals = [nm, n, jobs_pie_user['value'][jindex[nm]], numpy.sum(ix).astype(int),\\\n",
    "          (None if numpy.isnan(numpy.nanmax(numpy.nanmax(SACCT_obj['Start'][ix]))) else mpd.num2date(numpy.nanmax(SACCT_obj['Start'][ix])) ),\\\n",
    "           SACCT_obj['Group'][ix].astype(str)[0],\\\n",
    "                ','.join(numpy.unique(SACCT_obj['Account'][ix]).astype(str)),\\\n",
    "                ','.join(numpy.unique(SACCT_obj['Partition'][ix]).astype(str))]\n",
    "    print(delim.join([str(x) for x in rw_vals]))\n",
    "#     print(f\"{nm.decode()}, {n}, {jobs_pie_user['value'][jindex[nm]]},\\\n",
    "#           {mpd.num2date(max(SACCT_obj['Start'][ix]))}, {SACCT_obj['Group'][ix].astype(str)[0]},\\\n",
    "#                 {delim.join(numpy.unique(SACCT_obj['Account'][ix]).astype(str))},\\\n",
    "#                 {delim.join(numpy.unique(SACCT_obj['Partition'][ix]).astype(str))}\\\n",
    "#                 \")\n",
    "#\n",
    "# print('*** Jobs-time:')\n",
    "# print('**  Name,   n_jobs,   last_job_start')\n",
    "# for nm,n in jobs_pie_user[numpy.argsort(jobs_pie_user['value'])[::-1]]:\n",
    "#     ix = SACCT_obj['User'].astype(type(nm)) == nm\n",
    "#     print(f\"**  {nm.decode()}, {n}, {mpd.num2date(max(SACCT_obj['Start'][ix]))}, {SACCT_obj['Group'][ix][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG:\n",
    "print('** ', ax)\n",
    "print('** ', ax.get_xticklabels()[0].get_position()[0])\n",
    "print('** ', ax.get_xticks())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's get a some reports for specific users, namely Lauren and Eric's former student(s) to estimate\n",
    "#. requirements for their successors.\n",
    "#\n",
    "# Also, TODO: layer cake for active_cpus ?\n",
    "# NOTE: for up and coming \"how busy is the queue?\" reporting, something like this:\n",
    "# squeue -p serc --Format=jobid,jobarrayid,partition,username,state,timeused,timeleft,allocnodes,numnodes,numcpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpuh_jobs = SACCT_obj.get_cpu_hours(bin_size=1., n_points=5000)\n",
    "cpuh_layers = SACCT_obj.get_cpu_hours_layer_cake(bin_size=1.)\n",
    "\n",
    "fg = plt.figure(figsize=(20,16))\n",
    "ax1 = fg.add_subplot(2,2,1)\n",
    "ax2 = fg.add_subplot(2,2,2)\n",
    "ax3 = fg.add_subplot(2,2,3)\n",
    "ax4 = fg.add_subplot(2,2,4)\n",
    "ax1.grid()\n",
    "ax2.grid()\n",
    "#\n",
    "ax1.set_title('CPU Hours (per day)', size=16)\n",
    "ax2.set_title('Jobs (per day?)', size=16)\n",
    "#\n",
    "cpuh = cpuh_layers['cpu_hours']\n",
    "jobs = cpuh_layers['jobs']\n",
    "T = cpuh['time']\n",
    "\n",
    "print('*** ', cpuh.dtype)\n",
    "print('*** ', cpuh['time'][0:10])\n",
    "\n",
    "#\n",
    "z_cpuh = hpc_lib.plot_layer_cake(data=cpuh, layers=cpuh.dtype.names[1:], time_col='time', ax=ax1)\n",
    "z_jobs = hpc_lib.plot_layer_cake(data=jobs, layers=cpuh.dtype.names[1:], time_col='time', ax=ax2)\n",
    "#\n",
    "# pi charts. left: cpu-hours, right job-time\n",
    "# NOTE: these times will be in units of \"days\". Not important to convert them unless we need to quantify.\n",
    "pi_cpuh = hpc_lib.get_pie_slices(sum_data=SACCT_obj['Elapsed']*SACCT_obj['NCPUS'], slice_data=SACCT_obj['Account'])\n",
    "pi_cpuh_lbls = pi_cpuh['name'].astype(str)\n",
    "pi_cpuh_vls  = pi_cpuh['value'].astype(str)\n",
    "\n",
    "pi_jobs = hpc_lib.get_pie_slices(sum_data=SACCT_obj['Elapsed'], slice_data=SACCT_obj['Account'])\n",
    "pi_jobs_lbls = pi_jobs['name'].astype(str)\n",
    "pi_jobs_vls  = pi_jobs['value'].astype(str)\n",
    "#\n",
    "ax3.pie(pi_cpuh_vls, labels=pi_cpuh_lbls)\n",
    "ax4.pie(pi_jobs_vls, labels=pi_jobs_lbls)\n",
    "#\n",
    "ax1.legend(loc=0)\n",
    "ax2.legend(loc=0)\n",
    "#\n",
    "# fg.canvas.draw()\n",
    "# for ax in (ax1, ax2):\n",
    "#     lbls = [hpc_lib.simple_date_string(mpd.num2date(float(hpc_lib.fix_to_ascii(str(s.get_text()))) + SACCT_obj.dt_mpd_epoch ) ) \n",
    "#              for s in ax.get_xticklabels()]\n",
    "#     ax.set_xticklabels(lbls)\n",
    "#fg.canvas.draw()\n",
    "#lbls = [hpc_lib.simple_date_string(mpd.num2date(float(hpc_lib.fix_to_ascii(str(s.get_text())))) ) \n",
    "#         for s in ax1.get_xticklabels()]\n",
    "#ax1.set_xticklabels(lbls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('index, PI_group, CPUhours')\n",
    "ix = numpy.argsort([pi_cpuh['value']])\n",
    "\n",
    "pi_cpuh.sort(order='value')\n",
    "\n",
    "for k, (usr,cpuh) in enumerate(pi_cpuh[::-1]):\n",
    "    if hasattr(usr, 'decode'):\n",
    "        usr = usr.dedoce(())\n",
    "    print(f'{k}, {usr}, {cpuh*24.:.1f} ', )\n",
    "\n",
    "# for k, (pi,hrs) in enumerate(pi_cpuh[::-1]):\n",
    "#     print(f'{k}, {pi.decode()}, {pi_cpuh}')\n",
    "#CDF = numpy.cumsum(pi_cpuh['value'])\n",
    "\n",
    "fg = plt.figure(figsize=(10,8))\n",
    "ax = fg.add_subplot(1,1,1)\n",
    "#\n",
    "ax.plot(numpy.arange(len(pi_cpuh)), 24.*numpy.cumsum(pi_cpuh['value'][::-1])   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU Hours CDF\n",
    "fg = plt.figure(figsize=(16,8))\n",
    "ax1 = fg.add_subplot(1,2,1)\n",
    "ax2 = fg.add_subplot(1,2,2)\n",
    "h  = ax1.hist(pi_cpuh['value'], bins=len(pi_cpuh), cumulative=True, density=True, histtype='step', lw=3)\n",
    "h2 = ax2.hist(pi_cpuh['value'], bins=len(pi_cpuh), cumulative=False, density=False, histtype='step', lw=3)\n",
    "ax1.grid()\n",
    "ax1.set_title('CDF of CPU Hours, by PI group', size=16)\n",
    "ax1.set_xlabel('CPU Hours', size=16)\n",
    "\n",
    "ax2.set_yscale('log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SERC GPU activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPUs:\n",
    "For now, hijack the SACCT.get_active_cpus_layer_cake() function, but force the \"CPUs\" column to use GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_layers = SACCT_obj.get_active_cpus_layer_cake(layer_field='Account', NCPUs=SACCT_obj.get_NGPUs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gpu_layers.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# NOTE: here, N_cpu is GPUs, since GPU s were substituted into the CPU field to get the layers.\n",
    "pi_gpu_grps = [s for s in gpu_layers['N_cpu'].dtype.names[1:]]\n",
    "#print(f'** {pi_gpu_lbls}' )\n",
    "#\n",
    "NGPU = SACCT_obj.get_NGPUs()\n",
    "#\n",
    "#pi_gpu_vals = numpy.zeros(len(pi_gpu_lbls))\n",
    "pi_gpu_vals = []\n",
    "pi_gpu_lbls = []\n",
    "for k,g in enumerate(pi_gpu_grps):\n",
    "    ix = SACCT_obj.jobs_summary['Group'].astype(str)==g\n",
    "    #\n",
    "    n_gpus = numpy.sum(SACCT_obj.jobs_summary['Elapsed'][ix] * NGPU[ix])\n",
    "    if n_gpus <= 0.:\n",
    "        continue\n",
    "    #\n",
    "    pi_gpu_vals += [n_gpus]\n",
    "    pi_gpu_lbls += [f'{g}: {pi_gpu_vals[-1]:.1f}']\n",
    "#\n",
    "#print('** vals: ', pi_gpu_vals)\n",
    "#pi_gpu_lbls = [f'{s}: {v:.1f}' for s,v in zip(pi_gpu_lbls, pi_gpu_vals) ]\n",
    "\n",
    "\n",
    "fg = plt.figure(figsize=(16,14))\n",
    "ax1 = fg.add_subplot(2,1,1)\n",
    "ax2 = fg.add_subplot(2,2,3)\n",
    "ax3 = fg.add_subplot(2,2,4)\n",
    "ax1.grid()\n",
    "#ax2.grid()\n",
    "ax3.grid()\n",
    "#\n",
    "hpc_lib.plot_layer_cake(gpu_layers['N_cpu'], ax=ax1)\n",
    "z_gpus = ax1.lines[-1].get_ydata()\n",
    "x_gpus = ax1.lines[-1].get_xdata()\n",
    "#\n",
    "qs = [.5, .75, .9]\n",
    "qs_gpu = numpy.quantile(z_gpus, qs)\n",
    "#\n",
    "# and a trend analysis:\n",
    "A = numpy.vstack([x_gpus**n for n in range(2)]).T\n",
    "p = numpy.linalg.lstsq(A, z_gpus)[0]\n",
    "A = A[0::len(A)-1]\n",
    "ax1.plot(A[:,1], numpy.dot(A,p), ls='--', lw=3, label=f'trend: $b={p[1]:.2f}')\n",
    "#\n",
    "print('*** keys(): ', gpu_layers.keys())\n",
    "ax2.pie(pi_gpu_vals, labels=pi_gpu_lbls) \n",
    "ax2.legend(loc='upper right')\n",
    "#\n",
    "hh_cpus = ax3.hist(z_gpus, bins=100, cumulative=True, density=True, histtype='step', lw=3.)\n",
    "for x,y in zip(qs_gpu, qs):\n",
    "    #ax3.plot([0., qs_cpus[-1], qs_cpus[-1]], [qs[-1], qs[-1], 0.], ls='--', color='r', lw=2. )\n",
    "    ax3.plot([0., x, x], [y, y, 0.], ls='--', lw=2., label=f'{y*100.}th %: {x:.0f} gpus' )\n",
    "\n",
    "ax1.set_title('Active GPUs', size=16)\n",
    "ax3.legend(loc=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = plt.figure(figsize=(8,6))\n",
    "ax1 = fg.add_subplot(1,1,1)\n",
    "#\n",
    "hh_cpus = ax1.hist(z_gpus, bins=100, cumulative=True, density=True, histtype='step', lw=3.)\n",
    "for x,y in zip(qs_gpu, qs):\n",
    "    #ax3.plot([0., qs_cpus[-1], qs_cpus[-1]], [qs[-1], qs[-1], 0.], ls='--', color='r', lw=2. )\n",
    "    ax1.plot([0., x, x], [y, y, 0.], ls='--', lw=2., label=f'{y*100.}th %: {x:.0f} gpus' )\n",
    "    \n",
    "ax1.grid()\n",
    "ax1.legend(loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SACCT_obj.dtype.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big GPU groups:\n",
    "#ix_gpu_user_groups = numpy.argsort()\n",
    "# print('** ', pi_gpu_grps, len(pi_gpu_grps))\n",
    "# print('** ', pi_gpu_vals, len(pi_gpu_vals))\n",
    "#\n",
    "#ZZ = numpy.array([pi_gpu_grps, pi_gpu_vals]).T\n",
    "gpu_users = []\n",
    "for grp in pi_gpu_grps:\n",
    "    #print(f'** {grp}, {dt}*24.')\n",
    "    ix = SACCT_obj['Account'].astype(str) == grp\n",
    "    S = SACCT_obj[ix]\n",
    "    gpu_hours = 24.*numpy.sum(S['Elapsed'] * S['NGPUs'])\n",
    "    if gpu_hours == 0.:\n",
    "        continue\n",
    "    #\n",
    "    gpu_users += [[grp, gpu_hours]]\n",
    "    #print(f'** {grp}: {gpu_hours}')\n",
    "gpu_users.sort(key=lambda rw: rw[1])\n",
    "\n",
    "for g,dt in gpu_users[::-1]:\n",
    "    print(f'{g}: {dt:.2f}')\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_jobs_serc = SACCT_obj.active_jobs_cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serc_cpu_qs = numpy.quantile(cpu_jobs_serc['N_cpu'], [.5, .75, .9])\n",
    "print('** qs: ', serc_cpu_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('** ', numpy.unique(SACCT_obj['NGPUs']))\n",
    "#\n",
    "# for now, just manually add a max_mem value, in raw format...:\n",
    "# ...and I'm going to make it a little bigger, to avoid GB vs Gb (or whatver...) issues.\n",
    "#max_mem = 1024.*(1024.**3.)*1.1\n",
    "max_mem = 1024.*GB\n",
    "#\n",
    "ix_gpu = SACCT_obj['NGPUs']>0\n",
    "ix_gpu = numpy.logical_and(ix_gpu, SACCT_obj['ReqMem']<=max_mem)\n",
    "#\n",
    "ix_cpu = numpy.invert(ix_gpu)\n",
    "#\n",
    "# Diagnostic sequences and figures:\n",
    "mpG = numpy.zeros(len(SACCT_obj.jobs_summary))\n",
    "mpG[ix_gpu] = SACCT_obj['ReqMem'][ix_gpu] / SACCT_obj['NGPUs'][ix_gpu]\n",
    "mpG /= GB\n",
    "#\n",
    "ix_bigguns = numpy.argsort(mpG)\n",
    "print(f'** Bigguns indices: {ix_bigguns[-5:]}')\n",
    "print(f'** Bigguns: {mpG[ix_bigguns[:-5]]}')\n",
    "k_max = ix_bigguns[-1]\n",
    "print('** ', mpG)\n",
    "print('** ', SACCT_obj[-1])\n",
    "\n",
    "######\n",
    "fg = plt.figure(figsize=(8,6))\n",
    "ax = plt.gca()\n",
    "ax.plot(numpy.arange(len(mpG)), mpG)\n",
    "#ax.plot(SACCT_obj['Start'][ix_gpu], mpG[ix_gpu], ls='-', lw=2.)\n",
    "ax.grid()\n",
    "ax.set_xlabel('job sequence')\n",
    "ax.set_ylabel('mem/GPU')\n",
    "\n",
    "# Quantiles plot:\n",
    "ave_len=100\n",
    "mpg = numpy.array([x for x in mpG if x>0])\n",
    "gpu_quants = numpy.array([numpy.quantile(mpg[k-ave_len:k], [.5, .75, .95]) for k in range(ave_len, len(mpg))])\n",
    "\n",
    "fg = plt.figure(figsize=(8,6))\n",
    "ax = plt.gca()\n",
    "low, med, hi = (gpu_quants[:,k] for k in numpy.arange(gpu_quants.shape[1]))\n",
    "X = numpy.arange(len(low))\n",
    "\n",
    "l_lo, = plt.plot(X,low, ls='-', lw=1)\n",
    "ax.plot(X, med, ls='-', lw=3)\n",
    "l_hi, = plt.plot(X, hi, ls='-', lw=1)\n",
    "\n",
    "ax.fill_between(X, low, med, color=l_lo.get_color(), alpha=.2)\n",
    "ax.fill_between(X, med, hi, color=l_hi.get_color(), alpha=.2)\n",
    "ax.grid()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_len=25\n",
    "mpg = numpy.array([x for x in mpG if x>0])\n",
    "gpu_quants = numpy.array([numpy.quantile(mpg[k-ave_len:k], [.5, .75, .9]) for k in range(ave_len, len(mpg))])\n",
    "print('*** ', gpu_quants.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "sacct_gpus = SACCT_obj.jobs_summary[ix_gpu]\n",
    "#mem_per_gpu= SACCT_server[]\n",
    "#\n",
    "print('*** ', len(SACCT_obj.jobs_summary), len(sacct_gpus))\n",
    "#\n",
    "mem_per_gpu = (sacct_gpus['ReqMem']/sacct_gpus['NGPUs'])/GB\n",
    "mem_per_cpu = (SACCT_obj['ReqMem'][ix_cpu] / SACCT_obj['NCPUS'][ix_cpu])/GB\n",
    "\n",
    "rss_per_gpu = (sacct_gpus['MaxRSS']/sacct_gpus['NGPUs'])/GB\n",
    "\n",
    "#req_mem = SACCT_obj['ReqMem']/GB\n",
    "#\n",
    "fg = plt.figure(figsize=(10,8))\n",
    "ax1 = fg.add_subplot(1,1,1)\n",
    "#ax2 = fg.add_subplot(1,2,2)\n",
    "#\n",
    "hh_rss = ax1.hist(rss_per_gpu, bins=20, label='MaxRSS')\n",
    "hh_gpu = ax1.hist(mem_per_gpu, bins=20, histtype='step', label='ReqMem')\n",
    "\n",
    "##hh_cpu = ax2.hist(mem_per_cpu, bins=20)\n",
    "#hh_cpu = ax2.hist( (SACCT_obj['ReqMem']/(1024**3)), bins=2)\n",
    "#\n",
    "#ax1.set_yscale('log')\n",
    "#ax2.set_yscale('log')\n",
    "\n",
    "ax1.grid()\n",
    "#ax2.grid()\n",
    "#fg.suptitle('Requested Memory', size=16)\n",
    "ax1.set_title('ReqMem/GPU')\n",
    "ax1.set_xlabel('Memory per GPU', size=16)\n",
    "ax1.set_ylabel('Num. reqeusts', size=16)\n",
    "ax1.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReqMem/GPU, Tabular output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requested memory for GPU jobs, Tabular output.\n",
    "#\n",
    "# Tabular output:\n",
    "# Numbers of GPUs-hrs, per GPU/mem\n",
    "#\n",
    "#gpu_hrs_mem = {(k+1)*128:0 for k in range(8)}\n",
    "gpu_hrs_mem = numpy.array([[(k+1)*128, 0., 0., 0., 0.] for k in range(8)])\n",
    "\n",
    "#mpgs = numpy.array(list(gpu_hrs_mem.keys()))\n",
    "mpgs = gpu_hrs_mem[:,0]\n",
    "#print('** ', mpgs)\n",
    "\n",
    "print('** gpu_hrs_mem, Initialized:\\n', gpu_hrs_mem)\n",
    "# for kk, rw in enumerate(sacct_gpus):\n",
    "#     N = rw['NGPUs']\n",
    "#     Z = rw['ReqMem']/(GB*N)\n",
    "#     k = numpy.searchsorted( mpgs, Z )\n",
    "#     print(f'** mpg: {Z}, k: {k}')\n",
    "#     if kk>10: break\n",
    "    \n",
    "Ks = numpy.searchsorted( mpgs, sacct_gpus['ReqMem']/(GB*sacct_gpus['NGPUs']))\n",
    "total_gpus = numpy.sum(sacct_gpus['NGPUs'])\n",
    "total_hours = numpy.sum(sacct_gpus['NGPUs']*sacct_gpus['Elapsed']*24.)\n",
    "print('*** ', Ks[0:10])\n",
    "for k,rw in zip(Ks,sacct_gpus):\n",
    "    gpu_hrs_mem[k][1] += rw['NGPUs']\n",
    "    gpu_hrs_mem[k][2] += rw['NGPUs']*rw['Elapsed']*24.   # in hrs.\n",
    "#\n",
    "gpu_hrs_mem[:,3] = (100.*gpu_hrs_mem[:,1]/total_gpus)\n",
    "gpu_hrs_mem[:,4] = (100.*gpu_hrs_mem[:,2]/total_hours)\n",
    "\n",
    "print('** gpu_hrs_mem, completed?')\n",
    "for m,n,t,pn,pt in gpu_hrs_mem:\n",
    "    print(f'{m:.0f}  {n:.0f} {t:.2f} {pn:.2f}  {pt:.2f}')\n",
    "    #print(f'{m:f}  {n:f} {t:f} {pn:f}  {pt:f}')\n",
    "\n",
    "print('\\n\\nReqMem/GPU time distributions')\n",
    "print('m/gpu  n_gpus     gpu-time      pct_ngpu    pct_time')\n",
    "for m,n,t,pn,pt in gpu_hrs_mem:\n",
    "    \n",
    "    mm  = ('{: <6}'.format(m))\n",
    "    nn  = ('{: >7}'.format(f'{n:.2f}'))\n",
    "    tt  = ('{: >10}'.format(f'{t:.2f}'))\n",
    "    ppn = ('{: >10}'.format(f'{pn:.2f}'))\n",
    "    ppt = ('{: >10}'.format(f'{pt:.2f}'))\n",
    "    \n",
    "    print(f'{mm}  {nn} {tt} {ppn}%  {ppt}%')\n",
    "\n",
    "    \n",
    " #   '{: <5}'.format(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MaxRSS/GPU, Tabular output\n",
    "- Copy ReqMem/GPU above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('** ', sacct_gpus['MaxRSS'][0:10])\n",
    "print('** ', sacct_gpus['ReqMem'][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_hrs_mem = numpy.array([[(k+1)*128, 0., 0., 0., 0.] for k in range(8)])\n",
    "#\n",
    "# \"memory per gpu\"'s\n",
    "mpgs = gpu_hrs_mem[:,0]\n",
    "#\n",
    "print('** gpu_hrs_mem, Initialized:\\n', gpu_hrs_mem)\n",
    "#\n",
    "Ks = numpy.searchsorted( mpgs, sacct_gpus['MaxRSS']/(GB*sacct_gpus['NGPUs']))\n",
    "total_gpus = numpy.sum(sacct_gpus['NGPUs'])\n",
    "total_hours = numpy.sum(sacct_gpus['NGPUs']*sacct_gpus['Elapsed']*24.)\n",
    "print('*** ', Ks[0:10])\n",
    "for k,rw in zip(Ks,sacct_gpus):\n",
    "    if k>=len(gpu_hrs_mem) or numpy.isnan(rw['MaxRSS']):\n",
    "        continue\n",
    "    #\n",
    "    try:\n",
    "        gpu_hrs_mem[k][1] += rw['NGPUs']\n",
    "        gpu_hrs_mem[k][2] += rw['NGPUs']*rw['Elapsed']*24.   # in hrs.\n",
    "    except:\n",
    "        print(f'** EXCEPTION: MaxRSS={rw[\"MaxRSS\"]}, k={k}')\n",
    "        raise Exception()\n",
    "#\n",
    "gpu_hrs_mem[:,3] = (100.*gpu_hrs_mem[:,1]/total_gpus)\n",
    "gpu_hrs_mem[:,4] = (100.*gpu_hrs_mem[:,2]/total_hours)\n",
    "\n",
    "print('** gpu_hrs_mem, completed?')\n",
    "for m,n,t,pn,pt in gpu_hrs_mem:\n",
    "    print(f'{m:.0f}  {n:.0f} {t:.2f} {pn:.2f}  {pt:.2f}')\n",
    "    #print(f'{m:f}  {n:f} {t:f} {pn:f}  {pt:f}')\n",
    "\n",
    "\n",
    "print('\\n\\nMaxRSS/GPU time allocations')\n",
    "print('m/gpu   n_gpus    gpu-time       pct_ngpu   pct_time')\n",
    "for m,n,t,pn,pt in gpu_hrs_mem:\n",
    "    \n",
    "    mm  = ('{: <6}'.format(m))\n",
    "    nn  = ('{: >7}'.format(f'{n:.2f}'))\n",
    "    tt  = ('{: >10}'.format(f'{t:.2f}'))\n",
    "    ppn = ('{: >10}'.format(f'{pn:.2f}'))\n",
    "    ppt = ('{: >10}'.format(f'{pt:.2f}'))\n",
    "    \n",
    "    print(f'{mm}  {nn} {tt} {ppn}%  {ppt}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Jobs: ReqMem and MaxRSS per GPU and per Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('** ', numpy.unique(SACCT_obj['NGPUs']))\n",
    "#ix_gpu = SACCT_obj['NGPUs']>0\n",
    "#ix_cpu = numpy.invert(ix_gpu)\n",
    "#\n",
    "sacct_gpus = SACCT_obj.jobs_summary[ix_gpu]\n",
    "ix_cpu = numpy.invert(ix_gpu)\n",
    "#mem_per_gpu= SACCT_server[]\n",
    "#\n",
    "print('*** ', len(SACCT_obj.jobs_summary), len(sacct_gpus))\n",
    "#\n",
    "#max_rss_gpu = sacct_gpus['MaxVMSize']/GB\n",
    "max_rss_gpu = sacct_gpus['MaxRSS']/GB\n",
    "req_mem_gpu = sacct_gpus['ReqMem']/GB\n",
    "#\n",
    "rss_per_gpu  = max_rss_gpu/sacct_gpus['NGPUs']\n",
    "req_mem_per_gpu = req_mem_gpu/sacct_gpus['NGPUs']\n",
    "#mem_per_cpu = (SACCT_obj['MaxRSS'][ix_cpu] / SACCT_obj['NCPUS'][ix_cpu])\n",
    "#\n",
    "# quantiles:\n",
    "qs = [.5, .75, .90, .95, .99]\n",
    "#\n",
    "qs_rss_per_gpu  = numpy.quantile(rss_per_gpu[numpy.invert(numpy.isnan(rss_per_gpu))], qs)\n",
    "qs_rss          = numpy.quantile(max_rss_gpu[numpy.invert(numpy.isnan(max_rss_gpu))], qs)\n",
    "#\n",
    "# Requested Memory per gpu and per node (for GPU jobs)\n",
    "qs_rm_per_gpu  = numpy.quantile(req_mem_per_gpu[numpy.invert(numpy.isnan(req_mem_per_gpu))], qs)\n",
    "qs_rm_per_node = numpy.quantile(req_mem_gpu[numpy.invert(numpy.isnan(req_mem_gpu))], qs)\n",
    "\n",
    "print(f'** Quantiles: ({qs})')\n",
    "print(f'rss/gpu: {qs_rss_per_gpu}')\n",
    "print(f'rss/node: {qs_rss}')\n",
    "print(f'req_mem/gpu: {qs_rm_per_gpu}')\n",
    "print(f'req_mem/node: {qs_rm_per_node}')\n",
    "#\n",
    "fg = plt.figure(figsize=(10,12))\n",
    "ax1 = fg.add_subplot(2,2,1)\n",
    "ax2 = fg.add_subplot(2,2,2)\n",
    "ax3 = fg.add_subplot(2,2,3)\n",
    "ax4 = fg.add_subplot(2,2,4)\n",
    "#\n",
    "hh_gpu      = ax1.hist(rss_per_gpu, bins=20, density=True, label='MaxRSS')\n",
    "hh_rmem_gpu = ax1.hist(req_mem_per_gpu, bins=20, density=True, label='ReqMem', histtype='step')\n",
    "#\n",
    "hh_gpu      = ax3.hist(rss_per_gpu, bins=20, cumulative=True, density=True, label='MaxRSS')\n",
    "hh_rmem_gpu = ax3.hist(req_mem_per_gpu, bins=20, cumulative=True, histtype='step', density=True, label='ReqMem')\n",
    "for x,y in zip(qs_rss_per_gpu, qs):\n",
    "    ax3.plot([0., x, x], [y, y, 0.], ls='--', lw=2., label=f'{y*100.}th %: {x:.2f} GB/GPU' )\n",
    "# for x,y in zip(qs_rm_per_gpu, qs):\n",
    "#     ax3.plot([0., x, x], [y, y, 0.], ls='-.', lw=2., label=f'm{y*100.}th %: {x:.2f} GB/GPU' )\n",
    "\n",
    "\n",
    "ax1.set_yscale('log')\n",
    "ax2.set_yscale('log')\n",
    "\n",
    "\n",
    "#hh_cpu = ax2.hist(mem_per_cpu, bins=20)\n",
    "hh_cpu     = ax2.hist(max_rss_gpu, bins=20, density=True, label='MaxRSS')\n",
    "hh_req_mem = ax2.hist(req_mem_gpu, bins=20, histtype='step', density=True, label='ReqMem')\n",
    "#\n",
    "hh_cpu     = ax4.hist(max_rss_gpu, bins=20, cumulative=True, density=True, label='MaxRSS')\n",
    "hh_req_mem = ax4.hist(req_mem_gpu, bins=20, histtype='step', cumulative=True, density=True, label='ReqMem')\n",
    "for x,y in zip(qs_rss, qs):\n",
    "    ax4.plot([0., x, x], [y, y, 0.], ls='--', lw=2., label=f'{y*100.}th %: {x:.2f} GB/node' )\n",
    "# for x,y in zip(qs_rm_per_node, qs):\n",
    "#     ax4.plot([0., x, x], [y, y, 0.], ls='-.', lw=2., label=f'm{y*100.}th %: {x:.2f} GB/node' )\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "ax1.set_title('MaxRSS,ReqMem, per-gpu')\n",
    "ax2.set_title('MaxRSS, ReqMem, per-node')\n",
    "#\n",
    "#ax3.set_title('RSS,ReqMem, per-cpu')\n",
    "#ax4.set_title('MaxRSS,ReqMem, per-node (CPU)')\n",
    "\n",
    "for ax in [ax1, ax2, ax3, ax4]:\n",
    "    ax.legend(loc=0)\n",
    "    ax.grid()\n",
    "fg.suptitle('MaxRSS, ReqMem for GPU Jobs', size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('** ', req_mem_per_gpu[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_wait_times = sacct_gpus['Start'] - sacct_gpus['Submit']\n",
    "\n",
    "fg = plt.figure(figsize=(10,8))\n",
    "ax1 = fg.add_subplot(1,1,1)\n",
    "\n",
    "#hw = ax1.hist(gpu_wait_times, bins=10, histtype='step', density=True)\n",
    "do_log=False\n",
    "for m in numpy.arange(1,8):\n",
    "    M0 = m*128.\n",
    "    M1 = (m+1)*128\n",
    "    #\n",
    "    ix = numpy.logical_and(req_mem_per_gpu>M0, req_mem_per_gpu<=M1)\n",
    "    hw = ax1.hist(24.*gpu_wait_times[ix], bins=20, histtype='step', label=M1, density=True, lw=3,log=do_log)\n",
    "    \n",
    "\n",
    "ax1.grid()\n",
    "ax1.legend(loc=0)\n",
    "ax1.set_title('GPU Wait times, for mem/GPU')\n",
    "ax1.set_ylabel('Number of jobs')\n",
    "ax1.set_xlabel('Wait time (days?)')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Seasonality reports:\n",
    "NOTE: Some reports being moved to hpc_reports module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cpu_seasonality = SACCT_obj.active_cpu_jobs_per_day_hour_report(qs=[.45, .5, .9], periodic_projection='polar')\n",
    "\n",
    "cpu_seasonality = SACCT_obj.active_cpu_jobs_per_day_hour_report(qs=[.45, .5, .9], periodic_projection=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SACCT_rep = hpc_reports.SACCT_report_handler(SACCT_obj=SACCT_obj, Short_title='SERC, 2023-4',\n",
    "#                                 Full_title=\"SERC HPC Analytics, April 2023\", out_path='output/SERC_202304',\n",
    "#                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zz = SACCT_rep.cpu_hourly_activity_report()\n",
    "\n",
    "t_end = SACCT_obj['End']\n",
    "ix = numpy.isnan(t_end)\n",
    "print('** ', numpy.sum(numpy.invert(ix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  A Group report:\n",
    "- specify group; all partitions.\n",
    "- This is nominally (a version of) a standard report we might run for a PI group -- or at least this is how we produce the SACCT_obj for that group)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# A bunch of group reports!\n",
    "#  Well, a prototpy of that anaywayt.\n",
    "#\n",
    "# provide a list of valid PI_Groups (SACCT \"Group\" or possibly \"Account\" (which is the. same on Sherlock))\n",
    "\n",
    "PI_Groups=['pi2', 'pi2', ...]\n",
    "#\n",
    "#['gorle', 'lou', 'oneillm', 'ramr', 'aditis2', 'jaramilo', 'horne']\n",
    "cpu_hour_totals={}\n",
    "#\n",
    "for k_grp, grp_group in enumerate(PI_Groups):\n",
    "    #grp_group='oneillm'\n",
    "    #break\n",
    "#     if k_grp >= 5 and False:\n",
    "#         print('** BREAKing...')\n",
    "#         break\n",
    "    #\n",
    "    break\n",
    "    #n_cpus=10\n",
    "    print(f'** Group: {grp_group}')\n",
    "    #continue\n",
    "    #\n",
    "    grp_partition=None\n",
    "    verbose=False\n",
    "    SACCT_obj_grp = hpc_lib.SACCT_data_direct(group=grp_group, partition=grp_partition, start_date=str(start_date),\n",
    "                                             n_cpu=os.environ['SLURM_CPUS_ON_NODE'], verbose=False, delim=delim_sacct,\n",
    "                                             end_date=str(end_date), keep_raw_data=False)\n",
    "    \n",
    "    if len(SACCT_obj_grp)==0:\n",
    "        print(f'*** *** Group: {grp_group} has no data')\n",
    "        print(f'*** ***   Total CPU-hours[grp_group]: 0')\n",
    "        cpu_hour_totals[grp_group]=0.\n",
    "        #\n",
    "        continue\n",
    "    cpuh_total = numpy.sum(SACCT_obj_grp[\"Elapsed\"]*SACCT_obj_grp[\"NCPUS\"])\n",
    "    cpu_hour_totals[grp_group]=cpuh_total\n",
    "    print(f'** TOTAL CPU-hours [{grp_group}]: {cpuh_total:.2f}')\n",
    "    #continue\n",
    "\n",
    "    # Active CPUs layercake:\n",
    "    try:\n",
    "        fg_cpu_lc_acct = SACCT_obj_grp.report_activecpus_jobs_layercake_and_CDFs(group_by='Partition',\n",
    "                                                                                 ave_N_layers=15,\n",
    "                                                                                 ave_len_days=5.)\n",
    "\n",
    "        ax = fg_cpu_lc_acct.axes[0]\n",
    "        ln_ = ax.lines[0]\n",
    "        X = ln_.get_xdata()\n",
    "        #\n",
    "        ax.plot(X[0::(len(X)-1)], (12*24)*numpy.ones(2), ls='--', lw=3)\n",
    "        ax.set_title(f'Group: {grp_group}')\n",
    "    except:\n",
    "        print(f'*** EXCEPTION: activecpus_jobs_layercake_and_CDFS({grp_group}) failed')\n",
    "\n",
    "    ####################################\n",
    "    #\n",
    "\n",
    "\n",
    "#     cpu_seasonality_group = SACCT_obj_grp.active_cpu_jobs_per_day_hour_report(qs=[.45, .5, .9],\n",
    "#                                                                               periodic_projection='polar')\n",
    "    \n",
    "    \n",
    "    #\n",
    "    # plot_pie(sum_data=self['Elapsed']*self['NCPUS'], slice_data=self[group_by], ax=ax3, \n",
    "    #wedgeprops=wedgeprops, autopct=autopct, slice_names=cpuh.dtype.names[1:])\n",
    "\n",
    "    fg = plt.figure(figsize=(8,6))\n",
    "    ax1 = fg.add_subplot(1,1,1)\n",
    "    users_cpuh = hpc_lib.plot_pie(sum_data=SACCT_obj_grp['Elapsed']*SACCT_obj_grp['NCPUS'],\n",
    "    slice_data=SACCT_obj_grp['User'], ax=ax1)\n",
    "    ax1.set_title(f'Group: {grp_group}: By User')\n",
    "\n",
    "    fg = plt.figure(figsize=(8,6))\n",
    "    ax = fg.add_subplot(1,1,1)\n",
    "    #\n",
    "    users_cpuh = hpc_lib.plot_pie(sum_data=SACCT_obj_grp['Elapsed']*SACCT_obj_grp['NCPUS'],\n",
    "    slice_data=SACCT_obj_grp['Partition'], ax=ax)\n",
    "    ax.set_title(f'Group: {grp_group}: By Partition')\n",
    "\n",
    "    #################################\n",
    "    #\n",
    "#     fg = plt.figure(figsize=(10,6))\n",
    "#     ax = fg.add_subplot(1,1,1)\n",
    "#     #\n",
    "#     # users layercake:P\n",
    "#     users_apc_lc, users_jobs_lc = SACCT_obj_grp.get_active_cpus_layer_cake(layer_field='User').values()\n",
    "#     #print('*** dtype: ', users_apc_lc.dtype.names)\n",
    "#     zz = hpc_lib.plot_layer_cake(data=users_apc_lc, ax=ax, ave_len=15)\n",
    "#     ax.set_title('Group Users layercake')\n",
    "#     ax.legend(loc=0)\n",
    "#     ax.grid()\n",
    "#     ax.set_ylabel('Active CPUs')\n",
    "    \n",
    "#     N_users = len(users_apc_lc.dtype.names)-1\n",
    "#     #ax.plot(zz[0::(len(zz)-1),0], numpy.ones(2)*500*N_users, ls='--', lw=3., color='r'   )\n",
    "\n",
    "#     # to get individual user plots, for now, just do it the stupid way and de-layercake the output.\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cpu_hour_totals_copy = {'bakerjw': 32624.104317129608, 'aboehm': 0.0, 'billingt': 13.974467592592593, 'borja': 5507.455127314815, 'criddle': 0.0, 'jennadavis': 0.0, 'ggd': 17170.486006944444, 'fischer': 351.9669097222221, 'smfletch': 25.086782407407405, 'freyberg': 0.0, 'gorle': 185431.8845023148, 'hildemann': 0.0, 'jacobson': 0.0, 'risheej': 1.3362268518518519, 'ask': 0.0, 'peterk': 0.0, 'law': 0.0, 'mlepech': 207.02855324074076, 'linder': 6208.664074074074, 'luthy': 0.0, 'mauter': 471.8530439814815, 'mime': 0.0, 'wamitch': 18.428032407407404, 'noh': 781.4609953703706, 'osmank': 0.0006018518518518519, 'nto': 0.0, 'ramr': 182596.4798958333, 'bsimpson': 3752.3805092592597, 'quacks': 174.7665277777773, 'koseff': 0.0, 'stephen': 158.29505787037036}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job size distribuitons\n",
    "#### And other criteria for GCP allocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "groups = PI_Groups\n",
    "\n",
    "n_g = len(groups)\n",
    "fg = plt.figure(figsize=(10, 6*n_g))\n",
    "#fg2 = plt.figure(figsize=(10, 4*n_g))\n",
    "\n",
    "print('** ')\n",
    "#axes = []\n",
    "for k,grp in enumerate(groups):\n",
    "    print(f'** {grp}')\n",
    "    if k>=0: break\n",
    "    # not sure this index is being created correctly:\n",
    "    ix = numpy.array([(g.decode() if isinstance(g,bytes) else g)==grp for g in SACCT_obj.jobs_summary['Account']])\n",
    "    print('** ix: ', ix[0:10])\n",
    "    jobs = SACCT_obj.jobs_summary[ix]\n",
    "    #jobs = SACCT_obj.jobs_summary[(SACCT_obj.jobs_summary['Group']==grp)]\n",
    "    \n",
    "    ax1 = fg.add_subplot(n_g, 2, 2*k + 1)\n",
    "    ax2 = fg.add_subplot(n_g, 2, 2*k + 2)\n",
    "    ax1.set_title(f'Group: {grp}: Nodes')\n",
    "    ax2.set_title(f'Group: {grp}: NCPUs')\n",
    "    #\n",
    "    ax1.grid()\n",
    "    ax2.grid()\n",
    "    #\n",
    "    nbins=30\n",
    "    h1 = ax1.hist(jobs['NNodes'], bins=nbins)\n",
    "    h2 = ax2.hist(jobs['NCPUS'], bins=nbins)\n",
    "    #\n",
    "    ax1.set_xlabel('NNodes', size=16)\n",
    "    ax2.set_xlabel('NCPUs', size=16)\n",
    "    # User LayerCake:\n",
    "    #\n",
    "    # TODO: integrate into fg ? or separate 1 fg per group?\n",
    "    #ax3 = fg2.add_subplot(n_g, 1, k+1)\n",
    "    zz = SACCT_obj.report_activecpus_jobs_layercake_and_CDFs(group_by='User', jobs_summary=jobs)\n",
    "    #ax3.set_title(f'Group: {grp} Layer-Cake, by user')\n",
    "    #ax3.set_xlabel('time', size=16)\n",
    "    #ax2.set_ylabel('Active CPUs', size=16)\n",
    "    plt.gcf().suptitle(f'Group: {grp}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaxVMSize (or MaxRSS) analysis for CPUs\n",
    "- Turns out that MaxRSS reports the \"largest\" memory allocation for a job, which is not necessarily (???) the actual memory required.\n",
    "- It seems that MaxVMSize is a more accurate (it tents to be bigger anyway...) measure of the actual memory required, and may be sum_{over steps?} (RSS).\n",
    "- So the concern is that the MaxRSS analysis looks REALLY low for MPI jobs, and variuos forums report jobs failing with OoM when MaxRSS shows loads of available memory (like 10% allocated memory)\n",
    "- One example given, suggesting that MaxRSS should be a valid measure of used memory, and predictor of whether a job will fail with OoM, disccusses dynamically allocated arrays (in Fortran), where `X` memory is allocated, then `x` memory is filled. The authors suggest that MaxRSS will show `x`, maybe MaxVMSize will show `X` ?\n",
    "- Alternately, MaxVMSize shows the sum of the RSS for all the job steps? But nominally, should not the memory for those job steps be wiped clear?\n",
    "- In any case, for now -- for this analysis, we will use MaxVMSize, since it is a little bit bigger, and so seems to be providing better resolution (of some sort?) of the resource use. AT this time, both analyses lead to similar conclusions with respect to how to use Sherlock resources and which new resources to purchase.\n",
    "- On the other hand... `MaxVMSize` sometimes produces values (MUCH!) larger than the system memory. I think `MaxVMSize` allows for virtual memory constructs? Or Declarations of WAY too much memory, so long as it does not get filled?\n",
    "- But Stephane suggests that `MaxRSS` is still the better choice -- that it reports \"resident\" memory, where `MaxVMSize` can report swap or linked libraries (which might not be resident. See:\n",
    "\n",
    "    https://www.baeldung.com/linux/resident-set-vs-virtual-memory-size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('** ', len((SACCT_obj['MaxRSS'].astype('>f8')/SACCT_obj['NCPUS'].astype('>f8'))))\n",
    "# print('** ', (SACCT_obj['MaxRSS'].astype('>f8')/SACCT_obj['NCPUS'].astype('>f8'))[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ix1 = numpy.logical_and(SACCT_obj['NNodes']==1, SACCT_obj['State'].astype(str)=='COMPLETED')\n",
    "ix1 = numpy.logical_and(SACCT_obj['NTasks']==1, SACCT_obj['State'].astype(str)=='COMPLETED')\n",
    "#ix_mpi = numpy.logical_and(SACCT_obj['NTasks']>1, SACCT_obj['State'].astype(str)=='COMPLETED')\n",
    "ix_mpi = numpy.logical_and(SACCT_obj['NNodes']>1, SACCT_obj['State'].astype(str)=='COMPLETED')\n",
    "ix_gpu = (SACCT_obj['NGPUs']>1)\n",
    "\n",
    "#\n",
    "#MemVar = 'MaxVMSize'\n",
    "MemVar = 'MaxRSS'\n",
    "# maxrss/cpu and maxrss/node\n",
    "# Let's see what (some of?) these look like when we use MaxVMSize instead...\n",
    "max_rss_per_cpu_single = (1./GB)*(SACCT_obj[MemVar].astype('>f8')/SACCT_obj['NCPUS'].astype('>f8'))[ix1]\n",
    "#max_rss_per_cpu_single = (1./GB)*(SACCT_obj['MaxVMSize'].astype('>f8')/SACCT_obj['NCPUS'].astype('>f8'))[ix1]\n",
    "max_rss_per_cpu_single = max_rss_per_cpu_single[numpy.invert(numpy.isnan(max_rss_per_cpu_single).astype(bool))]\n",
    "#\n",
    "#\n",
    "max_rss_per_node_single = (1./GB)*(SACCT_obj[MemVar].astype('>f8'))[ix1]\n",
    "#max_rss_per_node_single = (1./GB)*(SACCT_obj['MaxVMSize'].astype('>f8'))[ix1]\n",
    "max_rss_per_node_single = max_rss_per_node_single[numpy.invert(numpy.isnan(max_rss_per_node_single).astype(bool))]\n",
    "\n",
    "# this is not right(yet), and might be hard to tease out.\n",
    "#max_rss_per_cpu_mpi = (SACCT_obj['MaxRSS']*SACCT_obj['NNodes']/(SACCT_obj['NCPUS']))[SACCT_obj['NNodes']>1]\n",
    "max_rss_per_cpu_mpi = (1./GB)*(SACCT_obj[MemVar].astype('>f8')*SACCT_obj['NTasks'].astype('>f8')/SACCT_obj['NCPUS'].astype('>f8'))[ix_mpi]\n",
    "#max_rss_per_cpu_mpi = (1./GB)*(SACCT_obj['MaxVMSize'].astype('>f8')*SACCT_obj['NTasks'].astype('>f8')/SACCT_obj['NCPUS'].astype('>f8'))[ix_mpi]\n",
    "max_rss_per_cpu_mpi = max_rss_per_cpu_mpi[numpy.invert(numpy.isnan(max_rss_per_cpu_mpi).astype(bool))]\n",
    "#\n",
    "# NOTE: \"per_node\" is really \"per_task\", for MPI or SPP/OMP jobs.\n",
    "max_rss_per_node_mpi = (1./GB)*(SACCT_obj[MemVar].astype('>f8'))[ix_mpi]\n",
    "#max_rss_per_node_mpi = (1./GB)*(SACCT_obj['MaxVMSize'].astype('>f8'))[ix_mpi]\n",
    "max_rss_per_node_mpi = max_rss_per_node_mpi[numpy.invert(numpy.isnan(max_rss_per_node_mpi).astype(bool))]\n",
    "#\n",
    "max_rss_per_cpu_single = max_rss_per_cpu_single[ (max_rss_per_cpu_single < 16.)]\n",
    "max_rss_per_cpu_mpi    = max_rss_per_cpu_mpi[ (max_rss_per_cpu_mpi < 16.)]\n",
    "#\n",
    "# quantiles:\n",
    "qs = [.5, .75, .95]\n",
    "qs_rss = [.5, .75, .90, .99]\n",
    "#\n",
    "qs_spp  = numpy.quantile(max_rss_per_cpu_single, qs_rss)\n",
    "qs_mpi  = numpy.quantile(max_rss_per_cpu_mpi, qs_rss)\n",
    "qs_node_spp = numpy.quantile(max_rss_per_node_single, qs_rss)\n",
    "qs_node_mpi = numpy.quantile(max_rss_per_node_mpi, qs_rss)\n",
    "#\n",
    "fg_spp = plt.figure(figsize=(10,12))\n",
    "fg_mpi = plt.figure(figsize=(10,12))\n",
    "#\n",
    "ax1 = fg_spp.add_subplot(2,2,1)\n",
    "ax2 = fg_spp.add_subplot(2,2,2)\n",
    "ax3 = fg_spp.add_subplot(2,2,3)\n",
    "ax4 = fg_spp.add_subplot(2,2,4)\n",
    "#\n",
    "ax5 = fg_mpi.add_subplot(2,2,1)\n",
    "ax6 = fg_mpi.add_subplot(2,2,2)\n",
    "ax7 = fg_mpi.add_subplot(2,2,3)\n",
    "ax8 = fg_mpi.add_subplot(2,2,4)\n",
    "#\n",
    "ax1.set_title(f'Single Task, {MemVar}/cpu PDF', size=16)\n",
    "ax2.set_title(f'Single Task, {MemVar}/cpu CDF', size=16)\n",
    "ax3.set_title(f'Single Task, {MemVar}/job PDF', size=16)\n",
    "ax4.set_title(f'Single Task, {MemVar}/job CDF', size=16)\n",
    "#\n",
    "ax5.set_title(f'Multi-Task, {MemVar}/cpu PDF', size=16)\n",
    "ax6.set_title(f\"Multi-Task, {MemVar}/cpu CDF\", size=16)\n",
    "ax7.set_title(f'Multi-Task, {MemVar}/task PDF', size=16)\n",
    "ax8.set_title(f'Multi-Task, {MemVar}/task CDF', size=16)\n",
    "#\n",
    "n_bins=50\n",
    "#\n",
    "h_single_cpu_pdf = ax1.hist(max_rss_per_cpu_single, bins=n_bins, density=True)\n",
    "h_single_cpu_pdf = ax2.hist(max_rss_per_cpu_single, bins=n_bins, cumulative=True, density=True)\n",
    "h_single_node_pdf = ax3.hist(max_rss_per_node_single, bins=n_bins, density=True)\n",
    "h_single_node_cdf = ax4.hist(max_rss_per_node_single, bins=n_bins, cumulative=True, density=True)\n",
    "#\n",
    "h_mpi_cpu_pdf = ax5.hist(max_rss_per_cpu_mpi, bins=n_bins, density=True)\n",
    "h_mpi_cpu_cdf = ax6.hist(max_rss_per_cpu_mpi, bins=n_bins*5, cumulative=True, density=True)\n",
    "#\n",
    "h_mpi_node_pdf = ax7.hist(max_rss_per_node_mpi, bins=n_bins, density=True)\n",
    "h_mpi_node_cdf = ax8.hist(max_rss_per_node_mpi, bins=n_bins*5, cumulative=True, density=True)\n",
    "#\n",
    "\n",
    "for x,y in zip(qs_spp, qs_rss):\n",
    "            ax2.plot([0., x, x], [y, y, 0.], ls='--', lw=2., label=f'{y*100.}th %: {x:.2f} GB/cpu' )\n",
    "for x,y in zip(qs_node_spp, qs_rss):\n",
    "    ax4.plot([0., x, x], [y, y, 0.], ls='--', lw=2., label=f'{y*100.}th %: {x:.2f} GB/job' )\n",
    "\n",
    "for x,y in zip(qs_mpi, qs_rss):\n",
    "    ax6.plot([0., x, x], [y, y, 0.], ls='--', lw=2., label=f'{y*100.}th %: {x:.2f} GB/cpu' )\n",
    "    \n",
    "for x,y in zip(qs_node_mpi, qs_rss):\n",
    "    ax8.plot([0., x, x], [y, y, 0.], ls='--', lw=2., label=f'{y*100.}th %: {x:.2f} GB/task' )\n",
    "        \n",
    "for ax in (ax1, ax2, ax3, ax4, ax5, ax6,ax7,ax8):\n",
    "    ax.grid()\n",
    "    ax.legend(loc='lower right')\n",
    "#\n",
    "ax5.set_xlim(-.1,4.)\n",
    "ax7.set_xlim(-.1,16.)\n",
    "\n",
    "ax6.set_xlim(-.1,6.)\n",
    "ax8.set_xlim(-.1, 15)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('** ', SACCT_obj.jobs_summary.dtype.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=0\n",
    "for k,rw in enumerate(SACCT_obj):\n",
    "    if rw['NTasks'] > 1:\n",
    "        print(f'** ', rw[ ['JobID', 'NNodes', 'NCPUS', 'NTasks', 'ReqMem', 'MaxRSS', 'AveRSS'] ],\n",
    "              \" ** \", rw['MaxRSS']*rw['NTasks']/(GB*rw['NCPUS']),\n",
    "              rw['MaxVMSize']*rw['NTasks']/(GB*rw['NCPUS']) )\n",
    "        j+=1\n",
    "    if j>100:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After-hours report(s)\n",
    "Note the discriminators for weekend might not be quite right. Specifically, the tails of the weekend are not (I don't think...) being calculated correctly.\n",
    "\n",
    "The approach of computing the time series and then using the modulus on the time series is a bit of a hack. It would probably be better to exactly break down each interval into time classes, then sum up.\n",
    "\n",
    "But for now, this is probably a reasonabl estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourlies = hpc_lib.get_cpu_hours(bin_size=7., d_t=1/24., verbose=0, \n",
    "                                 jobs_summary=SACCT_obj.jobs_summary)\n",
    "\n",
    "morning_pct = .3\n",
    "evening_pct = .7\n",
    "\n",
    "ix_wknd   = numpy.logical_and( (hourlies['time'])%7 >= 2., (hourlies['time'])%7 <= 3. )\n",
    "ix_afters = numpy.logical_or(hourlies['time']%1.<morning_pct , hourlies['time']%1>evening_pct)\n",
    "# \n",
    "# \"9 to 5!\"\n",
    "ix_dollies = numpy.logical_and(numpy.invert(ix_wknd), numpy.invert(ix_afters))\n",
    "\n",
    "cpuh_totals = numpy.array([numpy.sum(hourlies['cpu_hours'][ix]) \n",
    "                           for ix in [ix_wknd, ix_afters, ix_dollies]])\n",
    "cpuh_lbls = ['weekend', 'afters', 'dollies']\n",
    "#\n",
    "# we have calculated this with Dollies being .3 < t < .8,\n",
    "#. so business hours and after-hours have equal weight. Note that this is not actually\n",
    "#. 9-5, but seasonality reports suggested this was a reasonable definition, especially\n",
    "#. with people in different time zones, and considering that generally research is not\n",
    "#. contucted 9-5.\n",
    "#\n",
    "w_dollies = (evening_pct - morning_pct)*5.0\n",
    "w_afters  = 5.0 - w_dollies\n",
    "w_wknds   = 7.0 - (w_dollies + w_afters)\n",
    "\n",
    "print(f'** weights:\\n w_dollies: {w_dollies}\\n  w_afters: {w_afters}\\n  w_wknds: {w_wknds}')\n",
    "\n",
    "\n",
    "cpuh_normalized = cpuh_totals/numpy.array([w_wknds, w_afters, w_dollies])/7.\n",
    "#\n",
    "print('** ** ', cpuh_totals)\n",
    "\n",
    "#\n",
    "fg = plt.figure(figsize=(12,8))\n",
    "ax1 = fg.add_subplot(1,2,1)\n",
    "ax2 = fg.add_subplot(1,2,2)\n",
    "#\n",
    "ax1.pie(cpuh_totals, labels=cpuh_lbls, autopct='%1.1f%%')\n",
    "ax2.pie(cpuh_normalized, labels=cpuh_lbls, autopct='%1.1f%%')\n",
    "#\n",
    "ax1.set_title('9to5, raw')\n",
    "ax2.set_title('9to5, normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
