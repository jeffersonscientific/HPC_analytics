{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy\n",
    "import matplotlib\n",
    "import matplotlib.dates as mpd\n",
    "import pylab as plt\n",
    "import datetime as dtm\n",
    "import pytz\n",
    "import multiprocessing as mpp\n",
    "import pickle\n",
    "import os\n",
    "#\n",
    "# TODO: phase out unreferenced hpc_lib calls...\n",
    "import hpc_lib\n",
    "\n",
    "#\n",
    "#data_file_name='data/sacct_mazama_out_2.out'\n",
    "data_file_name = 'data/mazama_usage_20200506_tool8.out'\n",
    "#data_file_name = 'data/sacct_mazama_out_20200506a.out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_pickle = False\n",
    "pkl_name = \"{}.pkl\".format(os.path.splitext(data_file_name)[0])\n",
    "#\n",
    "if load_pickle:\n",
    "    with open(pkl_name, 'rb') as fin:\n",
    "        sacct_mazama=pickle.load(fin)\n",
    "    #\n",
    "else:\n",
    "    sacct_mazama = hpc_lib.SACCT_data_handler(data_file_name=data_file_name)\n",
    "    print('*** data handler created. Now Pickl it...')\n",
    "    #\n",
    "    \n",
    "    with open(pkl_name, 'wb') as fout:\n",
    "            #out_pkl = pickle.dump(sacct_demo.jobs_summary, fout)\n",
    "            out_pkl = pickle.dump(sacct_mazama, fout)\n",
    "    print('** pickle complete')\n",
    "#\n",
    "print('cell complete...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('doing anything?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sacct_mazama.cpu_usage=sacct_mazama.active_jobs_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** max_submit: 2020-05-06 14:47:13+00:00, max_start: 2020-05-06 14:47:13+00:00\n"
     ]
    }
   ],
   "source": [
    "max_submit, max_start = [mpd.num2date(numpy.nanmax(sacct_mazama.jobs_summary[cl])) for cl in ['Start', 'Submit'] ]\n",
    "print('*** max_submit: {}, max_start: {}'.format(*[mpd.num2date(numpy.nanmax(sacct_mazama.jobs_summary[cl])) for cl in ['Start', 'Submit'] ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#cpu_usage = sacct_mazama.active_jobs_cpu()\n",
    "cpu_usage = sacct_mazama.cpu_usage\n",
    "#\n",
    "bin_size=7\n",
    "cpu_weekly = sacct_mazama.active_jobs_cpu(bin_size=bin_size, t_min=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('** ', len(cpu_usage['time']))\n",
    "print('** ** ', sacct_mazama.data[0:5])\n",
    "print('** ', sacct_mazama.data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = plt.figure(figsize=(10,10))\n",
    "ax1 = fg.add_subplot('211')\n",
    "ax2 = fg.add_subplot('212', sharex=ax1)\n",
    "for ax in (ax1, ax2):\n",
    "    ax.grid()\n",
    "#\n",
    "ax1.plot(cpu_usage['time'], cpu_usage['N_jobs'], ls='-', lw=2., marker='')\n",
    "ax1.plot(cpu_weekly['time'], cpu_weekly['N_jobs'], ls='-', lw=2., marker='.')\n",
    "#\n",
    "ax2.plot(cpu_usage['time'], cpu_usage['N_cpu'], ls='-', lw=2., marker='')\n",
    "ax2.plot(cpu_weekly['time'], cpu_weekly['N_cpu'], ls='-', lw=2., marker='.')\n",
    "#\n",
    "\n",
    "ax1.set_title('Jobs', size=16)\n",
    "ax1.set_ylabel('$N_{jobs}$', size=16)\n",
    "#\n",
    "ax2.set_title('CPUs', size=16)\n",
    "ax2.set_ylabel('$N_{CPU}$', size=16)\n",
    "\n",
    "fg.canvas.draw()\n",
    "#\n",
    "# set ax3 labels to dates:\n",
    "# now format the datestrings...\n",
    "lbls = [hpc_lib.simple_date_string(mpd.num2date(float(s.get_text())) ) for s in ax1.get_xticklabels()]\n",
    "#print('*** ', lbls)\n",
    "#\n",
    "ax2.set_xticklabels(lbls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_bin_aggregates(XY, bin_mod=24, qs=[.25, .5, .75]):\n",
    "    # NOTE: this is not quite general purpose. it takes the input%1, then converts the fractional remainder\n",
    "    #. (modulus) to an integer(ish) by multiplying. Aka, t%1 gives the remaining fraction of a day (by standard\n",
    "    #. python date conventions); (t%1)*24 gives that in hours. But to convert this to DoW, we first have \n",
    "    #. to convert the numerical date to weeks, so we'd want (t-t_0)%7, or we could use this function, but\n",
    "    #. pass t=t_days/7., bin_mod=7, and really we'd want to do a phase shif to get DoW correctly.\n",
    "    XY=numpy.array(XY)\n",
    "    if XY.shape[0]==2:\n",
    "        X = XY[0,:]\n",
    "        Y = XY[1:]\n",
    "    else:\n",
    "        X = XY[:,0]\n",
    "        Y = XY[:,1]\n",
    "    #\n",
    "    #X_mod = ((X*bin_mod)%bin_mod).astype(int)\n",
    "    X_mod = ((X%1.)*bin_mod).astype(int)\n",
    "    #\n",
    "    stats_output=[]\n",
    "    for x in numpy.unique(X_mod):\n",
    "        ix = X_mod==x\n",
    "        this_Y = Y[ix]\n",
    "        stats_output += [numpy.append([x, numpy.mean(this_Y), numpy.std(this_Y)],\n",
    "                                      numpy.quantile(this_Y, qs))]\n",
    "    #\n",
    "    # TODO: convert this to a structured array. it looks (mostly) just like a record array, but it's not...\n",
    "    #.  and it's faster...\n",
    "    return numpy.core.records.fromarrays(numpy.array(stats_output).T, dtype=[('x', '>f8'), ('mean', '>f8'),\n",
    "                                                        ('stdev', '>f8')] + \n",
    "                                         [('q_{}'.format(q), '>f8') for q in qs])\n",
    "#\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instant_usage_report(qs=[.45, .5, .55], figsize=(14,10), cpu_usage=cpu_usage):\n",
    "    fg = plt.figure(figsize=(14,10))\n",
    "    #\n",
    "    ax1 = fg.add_subplot('231')\n",
    "    ax2 = fg.add_subplot('232')\n",
    "    ax3 = fg.add_subplot('233')\n",
    "    ax4 = fg.add_subplot('234')\n",
    "    ax5 = fg.add_subplot('235')\n",
    "    ax6 = fg.add_subplot('236')\n",
    "    axs = [ax1, ax2, ax3, ax4, ax5, ax6]\n",
    "    [ax.grid() for ax in axs]\n",
    "    #\n",
    "    qs = [.45, .5, .55]\n",
    "    qs_s = ['q_{}'.format(q) for q in qs]\n",
    "    print('*** qs_s: ', qs_s)\n",
    "\n",
    "    cpu_hourly = hpc_lib.time_bin_aggregates(XY=numpy.array([cpu_usage['time'], \n",
    "                                                     cpu_usage['N_cpu']]).T, qs=qs)\n",
    "    jobs_hourly = hpc_lib.time_bin_aggregates(XY=numpy.array([cpu_usage['time'],\n",
    "                                                      cpu_usage['N_jobs']]).T, qs=qs)\n",
    "    #\n",
    "    cpu_weekly = hpc_lib.time_bin_aggregates(XY=numpy.array([cpu_usage['time']/7.,\n",
    "                                                     cpu_usage['N_cpu']]).T, bin_mod=7., qs=qs)\n",
    "    jobs_weekly = hpc_lib.time_bin_aggregates(XY=numpy.array([cpu_usage['time']/7.,\n",
    "                                                      cpu_usage['N_jobs']]).T, bin_mod=7., qs=qs)\n",
    "    #\n",
    "    ix_pst = numpy.argsort( (jobs_hourly['x']-7)%24)\n",
    "    #\n",
    "    hh1 = ax1.hist(sorted(cpu_usage['N_jobs'])[0:int(1.0*len(cpu_usage))], bins=25, cumulative=False)\n",
    "    ax2.plot(jobs_hourly['x'], jobs_hourly['mean'], ls='-', marker='o', label='PST')\n",
    "    ax2.plot((jobs_hourly['x']), jobs_hourly['mean'][ix_pst], ls='-', marker='o', label='UTC')\n",
    "    ax3.plot(jobs_weekly['x'], jobs_weekly['q_0.5'], ls='-', marker='o', color='b')\n",
    "    ax3.plot(jobs_weekly['x'], jobs_weekly['mean'], ls='--', marker='', color='b')\n",
    "    ax3.fill_between(jobs_weekly['x'], jobs_weekly[qs_s[0]], jobs_weekly[qs_s[-1]],\n",
    "                     alpha=.1, zorder=1, color='b')\n",
    "    #\n",
    "    #\n",
    "    hh4 = ax4.hist(cpu_usage['N_cpu'], bins=25)\n",
    "    ax5.plot(cpu_hourly['x'], cpu_hourly['mean'], ls='-', marker='o', label='PST')\n",
    "    ax5.plot( (cpu_hourly['x']), cpu_hourly['mean'][ix_pst], ls='-', marker='o', label='UTC')\n",
    "    ax6.plot(cpu_weekly['x'], cpu_weekly['q_0.5'], ls='-', marker='o', color='b')\n",
    "    ax6.plot(cpu_weekly['x'], cpu_weekly['mean'], ls='--', marker='', color='b')\n",
    "    #\n",
    "    # TODO: can we simplyfy this qs syntax?\n",
    "    ax6.fill_between(cpu_weekly['x'], cpu_weekly[qs_s[0]], cpu_weekly[qs_s[-1]], alpha=.1, zorder=1, color='b')\n",
    "    #\n",
    "    #ax1.set_ylim(-5., 200)\n",
    "    ax1.set_title('$N_{jobs}$ Histogrm', size=16)\n",
    "    ax2.set_title('Hour-of-day job counts', size=16)\n",
    "    ax3.set_title('Day-of-week job counts', size=16)\n",
    "    #\n",
    "    ax4.set_title('$N_{cpu}$ Histogram', size=16)\n",
    "    ax5.set_title('Hour-of-day CPU counts', size=16)\n",
    "    ax6.set_title('Day-of-week CPU counts', size=16)\n",
    "    #\n",
    "    ax5.set_xlabel('Hour of Day (PST)')\n",
    "    plt.suptitle('Instantaneous Usage ', size=16)\n",
    "    #\n",
    "    ax2.legend(loc=0)\n",
    "    ax5.legend(loc=0)\n",
    "    #\n",
    "    for ax in (ax3, ax6):\n",
    "        ax.set_xticklabels(['', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])\n",
    "    #\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_hours = sacct_mazama.get_cpu_hours(bin_size=7, n_points=5000)\n",
    "\n",
    "daily_hours = sacct_mazama.get_cpu_hours(bin_size=1, n_points=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = plt.figure(figsize=(10,8))\n",
    "ax1 = plt.gca()\n",
    "ax1.grid()\n",
    "#\n",
    "ax1.plot(weekly_hours['time'], weekly_hours['cpu_hours']/7., ls='-', marker='.', label='bins=7 day', zorder=11)\n",
    "ax1.plot(daily_hours['time'], daily_hours['cpu_hours'], ls='-', marker='.', label='bins=1 day', zorder=5)\n",
    "\n",
    "\n",
    "#\n",
    "fg.canvas.draw()\n",
    "#\n",
    "# set ax3 labels to dates:\n",
    "# now format the datestrings...\n",
    "lbls = [hpc_lib.simple_date_string(mpd.num2date(float(s.get_text())) ) for s in ax1.get_xticklabels()]\n",
    "#print('*** ', lbls)\n",
    "#\n",
    "ax1.set_xticklabels(lbls)\n",
    "ax1.set_xlabel('Time $t$')\n",
    "ax1.set_ylabel('Daily CPU hours')\n",
    "ax1.set_title('Daily CPU hours')\n",
    "#\n",
    "ax1.legend(loc=0)\n",
    "\n",
    "ax1.plot(daily_hours['time'][0::len(daily_hours)-1], numpy.ones(2)*123*48*24, ls='--', marker='', lw=3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many active nodes do we have? looks like tasks/cpus show up as 1/thread, so 48 per node, so...\n",
    "n_max = numpy.max(daily_hours['cpu_hours'])\n",
    "#\n",
    "n_nodes = n_max/(24.*48.)\n",
    "#\n",
    "print('*** n_max={}, n_nodes={}'.format(n_max, n_nodes))\n",
    "#140000/(24*48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time of day(-like) compute volume requests.\n",
    "\n",
    "qs = [.5, .75, .95]\n",
    "#\n",
    "comp_vol_submit = sacct_mazama.get_submit_compute_vol_timeofday(qs=qs)\n",
    "comp_vol_start = sacct_mazama.get_submit_compute_vol_timeofday(time_col='Start', qs=qs)\n",
    "#\n",
    "fg = plt.figure(figsize=(12,6))\n",
    "ax1 = fg.add_subplot('121')\n",
    "ax2 = fg.add_subplot('122')\n",
    "ax1.grid()\n",
    "ax2.grid()\n",
    "#\n",
    "\n",
    "# N = numpy.sum(comp_vol_submit['cpu-time'])\n",
    "N = 1.\n",
    "ax1.plot(comp_vol_submit['time'], comp_vol_submit['cpu-time']/N,\n",
    "         ls='-', marker='o', lw=2., label='submit')\n",
    "#print('*** ', numpy.sum(comp_vol_submit['cpu-time']/numpy.sum(comp_vol_submit['cpu-time'])))\n",
    "#\n",
    "# N = numpy.sum(comp_vol_start['cpu-time'])\n",
    "N = 1 \n",
    "ax1.plot(comp_vol_start['time'], comp_vol_start['cpu-time']/N,\n",
    "         ls='-', marker='o', lw=2., label='start')\n",
    "#print('*** ', numpy.sum(comp_vol_start['cpu-time']/N))\n",
    "#\n",
    "#N=numpy.sum(comp_vol_submit['cpus'])\n",
    "N=1.\n",
    "ax2.plot(comp_vol_submit['time'], comp_vol_submit['cpus']/N, ls='-', marker='o', lw=2., label='submit')\n",
    "\n",
    "#N=numpy.sum(comp_vol_start['cpus'])\n",
    "N=1\n",
    "ax2.plot(comp_vol_start['time'], comp_vol_start['cpus']/N, ls='-', marker='o', lw=2., label='start')\n",
    "#\n",
    "#for k,cl in enumerate(comp_vol_tod.dtype.names[2:]):\n",
    "#    ax1.plot(comp_vol_tod['time'], comp_vol_tod[cl], ls='-', marker='o', lw=2., label='$q={}$'.format(qs[k]))\n",
    "#    break\n",
    "#\n",
    "ax1.legend(loc=0, numpoints=1)\n",
    "ax1.set_title('Compute Volume Requested, \\n$N_{CPU} \\cdot \\Delta t_{limit}$')\n",
    "ax1.set_xlabel('Hour of day')\n",
    "ax2.set_ylabel('Compute Vol.')\n",
    "\n",
    "ax2.set_title('CPUs Requested')\n",
    "ax3.set_xlabel('Hour of day')\n",
    "ax2.legend(loc=1, numpoints=1)\n",
    "\n",
    "#ax1.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute some distributions:\n",
    "print('*** ', sacct_mazama.jobs_summary.dtype.names)\n",
    "run_times = sacct_mazama.get_run_times()\n",
    "\n",
    "#\n",
    "fg = plt.figure(figsize=(12,8))\n",
    "ax1 = fg.add_subplot('221')\n",
    "ax2 = fg.add_subplot('222')\n",
    "#ax1a.set_yscale('log')\n",
    "ax3 = fg.add_subplot('223')\n",
    "ax4 = fg.add_subplot('224')\n",
    "ax1.grid()\n",
    "ax2.grid()\n",
    "ax3.grid()\n",
    "ax4.grid()\n",
    "#\n",
    "hh = ax1.hist(run_times, bins=50, cumulative=False, normed=True, log=True)\n",
    "hh1c = ax2.hist(run_times, bins=50, cumulative=True, normed=True, log=True, histtype='bar')\n",
    "#hh1c = ax2.plot(sorted(run_times), numpy.array(numpy.linspace(1./len(run_times), 1.,\n",
    "#                                                             len(run_times))), lw=3.0, zorder=11)\n",
    "#\n",
    "hh2 = ax3.hist(sacct_mazama.jobs_summary['NCPUS'], bins=50, normed=True, log=True)\n",
    "hh22 = ax4.hist(sacct_mazama.jobs_summary['NCPUS'], bins=50, normed=True, log=True,\n",
    "                 cumulative=True, histtype='bar', lw=3, zorder=11)\n",
    "#hh22 = ax4.hist(sacct_mazama.jobs_summary['NCPUS'], bins=50, normed=True, log=True,\n",
    "#                 cumulative=True, histtype='step', lw=3, zorder=11)\n",
    "#ax1.plot(run_times, ls='', marker='.')\n",
    "#print('*** ', run_times[0:20]*24, len(run_times), run_times.shape)\n",
    "#\n",
    "ax1.set_title('Run-time Distribution (days)')\n",
    "ax3.set_title('NCPUs Distribution')\n",
    "ax2.set_xlabel('Time (days)')\n",
    "ax4.set_xlabel('CPUS $N_{cpus}$')\n",
    "#\n",
    "ax2.set_title(\"(Cumulative)\")\n",
    "#ax4.set_title(\"(Cumulative)\")\n",
    "\n",
    "#ax2.set_xlim(-1,800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('** ', len(run_times), len(sacct_mazama.jobs_summary['NCPUS']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ix_rt = numpy.argsort(run_times)\n",
    "run_times_sorted = run_times.copy()\n",
    "run_times_sorted.sort()\n",
    "#\n",
    "k_2 = numpy.searchsorted(run_times_sorted, 2.0)\n",
    "k_7 = numpy.searchsorted(run_times_sorted, 7.0)\n",
    "k_14 = numpy.searchsorted(run_times_sorted, 14.0)\n",
    "\n",
    "#\n",
    "# k_2 = numpy.searchsorted(run_times[ix_rt], 2.0)\n",
    "# #k_7 = numpy.searchsorted(run_times[ix_rt], 7.0)\n",
    "# k_7 = k_2 + numpy.searchsorted( (run_times[ix_rt])[k_2:], 7.0)\n",
    "# k_14 = k_7 + numpy.searchsorted( (run_times[ix_rt])[k_7:], 14.0)\n",
    "#\n",
    "N=float(len(run_times))\n",
    "print('*** quantiles for t=2,7,14 days: {}, {}, {}'.format(float(k_2)/N, k_7/N, k_14/N))\n",
    "#\n",
    "# percent of jobs that use N<24 cores (aka, can run on a single node). Note that these are especially\n",
    "#. eligible for GCP.\n",
    "N_24 = numpy.sum(sacct_mazama.jobs_summary['NCPUS']<25)\n",
    "print('*** N_24/N={}'.format(N_24/N))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_stats = sacct_mazama.get_wait_stats()\n",
    "#\n",
    "fg = plt.figure(figsize=(10,10))\n",
    "ax1 = plt.gca()\n",
    "ax1.grid()\n",
    "#\n",
    "ax1.plot(wait_stats['ncpus'], wait_stats['mean'], ls='-', label='mean')\n",
    "ax1.plot(wait_stats['ncpus'], wait_stats['median'], ls='-', label='median')\n",
    "#\n",
    "#ax1.set_ylim(-.1, .5)\n",
    "ax1.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t0 = mpd.date2num(dtm.datetime(2019,9,2, tzinfo=pytz.timezone('UTC')))\n",
    "t0 = mpd.date2num(dtm.datetime(2019,12,30, tzinfo=pytz.timezone('UTC')))\n",
    "#\n",
    "bin_size=7\n",
    "cpu_weekly = sacct_mazama.active_jobs_cpu(bin_size=bin_size, t_min=t0)\n",
    "#\n",
    "fg = plt.figure(figsize=(10,10))\n",
    "plt.suptitle('Weekly Usage')\n",
    "ax1 = fg.add_subplot('211')\n",
    "ax2 = fg.add_subplot('212', sharex=ax1)\n",
    "for ax in (ax1, ax2):\n",
    "    ax.grid()\n",
    "#\n",
    "ax1.plot(cpu_weekly['time'], cpu_weekly['N_jobs'], ls='-', lw=2., marker='')\n",
    "ax2.plot(cpu_weekly['time'], cpu_weekly['N_cpu'], ls='-', lw=2., marker='')\n",
    "\n",
    "ax1.set_title('Jobs', size=16)\n",
    "ax1.set_ylabel('$N_{jobs}$', size=16)\n",
    "#\n",
    "ax2.set_title('CPUs', size=16)\n",
    "ax2.set_ylabel('$N_{CPU}$', size=16)\n",
    "\n",
    "fg.canvas.draw()\n",
    "#\n",
    "# set ax3 labels to dates:\n",
    "# now format the datestrings...\n",
    "lbls = [hpc_lib.simple_date_string(mpd.num2date(float(s.get_text())) ) for s in ax1.get_xticklabels()]\n",
    "print('*** ', lbls)\n",
    "#\n",
    "ax2.set_xticklabels(lbls)\n",
    "#\n",
    "plt.suptitle('Mazama Activity, $\\Delta t_{{binsize}}={}$ days'.format(bin_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group drill-down stats\n",
    "- Demo of how to get some sort of PI/group subsets.\n",
    "- More to come..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t0 = mpd.date2num(dtm.datetime(2019,9,2, tzinfo=pytz.timezone('UTC')))\n",
    "t0 = mpd.date2num(dtm.datetime(2019,12,30, tzinfo=pytz.timezone('UTC')))\n",
    "#\n",
    "# and get a list of users to construct an index:\n",
    "# $ finger dunham\n",
    "# Login: edunham         Name: Eric Dunham\n",
    "# Directory: /home/edunham             Shell: /bin/bash\n",
    "# Never logged in.\n",
    "# No mail.\n",
    "# No Plan.\n",
    "# [rcwhite@cees-mgmt0 ~]$ id edunham\n",
    "# uid=60367(edunham) gid=100(users) groups=100(users),203(tgp),70137(fs-erd)\n",
    "# [rcwhite@cees-mgmt0 ~]$ getent group | grep tgp\n",
    "# tgp:*:203:ooreilly,kashefi,malmq,axelwang,lwat054,glotto,chao2,bponemon,danmohad,sinux1,\n",
    "# gnava,eliasrh,dennis,zhuwq,yyang85,sbydlon,houyun,cstierns,mrivet,jlmaurer,myoder96,sozawa,schu3,\n",
    "# lbruhat,kallison,labraha2,kcoppess,edunham\n",
    "#\n",
    "users = 'ooreilly,kashefi,malmq,axelwang,lwat054,glotto,chao2,bponemon,danmohad,sinux1,\\\n",
    "gnava,eliasrh,dennis,zhuwq,yyang85,sbydlon,houyun,cstierns,mrivet,jlmaurer,myoder96,sozawa,\\\n",
    "schu3,lbruhat,kallison,labraha2,kcoppess,edunham'.split(',')\n",
    "users = [s for s in users if not s in ('myoder96', 'dennis')]\n",
    "#print('** users: ', users)\n",
    "#\n",
    "ix = numpy.array([s in users for s in sacct_mazama.jobs_summary['User'] ])\n",
    "#ix = numpy.array([True for s in sacct_mazama.jobs_summary['User'] ])\n",
    "#print('** ', (sacct_mazama.jobs_summary[ix])[0:20] )\n",
    "print('** DEBUG: sum(ix={})'.format(numpy.sum(ix)))\n",
    "#\n",
    "cpu_weekly = sacct_mazama.active_jobs_cpu(bin_size=7., t_min=t0, ix=ix)\n",
    "#\n",
    "fg = plt.figure(figsize=(10,10))\n",
    "ax1 = fg.add_subplot('211')\n",
    "ax2 = fg.add_subplot('212', sharex=ax1)\n",
    "for ax in (ax1, ax2):\n",
    "    ax.grid()\n",
    "#\n",
    "ax1.plot(cpu_weekly['time'], cpu_weekly['N_jobs'], ls='-', lw=2., marker='')\n",
    "ax2.plot(cpu_weekly['time'], cpu_weekly['N_cpu'], ls='-', lw=2., marker='')\n",
    "#\n",
    "plt.suptitle('Dunham Group')\n",
    "ax1.set_title('Jobs', size=16)\n",
    "ax1.set_ylabel('$N_{jobs}$', size=16)\n",
    "#\n",
    "ax2.set_title('CPUs', size=16)\n",
    "ax2.set_ylabel('$N_{CPU}$', size=16)\n",
    "\n",
    "fg.canvas.draw()\n",
    "#\n",
    "# set ax3 labels to dates:\n",
    "# now format the datestrings...\n",
    "lbls = [hpc_lib.simple_date_string(mpd.num2date(float(s.get_text())) ) for s in ax1.get_xticklabels()]\n",
    "print('*** ', lbls)\n",
    "#\n",
    "ax2.set_xticklabels(lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a table of weekly usage by group?\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    with open(data_file_name, 'r') as fin:\n",
    "        header_rw = fin.readline()\n",
    "        print('*** ', header_rw)\n",
    "\n",
    "    headers = header_rw.split('|')\n",
    "    k_group = headers.index('Group')\n",
    "    k_gid = headers.index('GID')\n",
    "    #\n",
    "    \n",
    "    with open(data_file_name, 'r') as fin:\n",
    "        for k,rw in enumerate(fin):\n",
    "            #if 'dunham' in rw: print('** ', rw)\n",
    "            #if 'dunham' in rw:\n",
    "            #    rws = rw.split('|')\n",
    "            #    print('** ', rws[k_group], rws[k_gid])\n",
    "            if 'Partition_Limit' in rw:\n",
    "                print('** ', rw)\n",
    "                k+=1\n",
    "                if k>10: break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rw in zip([1,2,3,4], [5,6,7,8], [9,10,11, 12]):\n",
    "    print('* ', rw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = numpy.array(numpy.zeros((10,3)), dtype=[('x', '>f8'), ('y', '>f8'), ('z', '>f8')])\n",
    "print('A ', A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
